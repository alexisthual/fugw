
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/01_brain_alignment/plot_4_aligning_high_res_volumes.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_01_brain_alignment_plot_4_aligning_high_res_volumes.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_01_brain_alignment_plot_4_aligning_high_res_volumes.py:


================================================================
High-resolution volume alignment of 2 individuals with fMRI data
================================================================

In this example, we align 2 low-resolution brain volumes
using 4 fMRI feature maps (z-score contrast maps).

.. GENERATED FROM PYTHON SOURCE LINES 10-20

.. code-block:: default


    import numpy as np
    import matplotlib.colors as colors
    import matplotlib.pyplot as plt

    from mpl_toolkits.axes_grid1 import make_axes_locatable
    from nilearn import datasets, image
    from fugw.mappings import FUGW, FUGWSparse
    from fugw.scripts import coarse_to_fine, lmds








.. GENERATED FROM PYTHON SOURCE LINES 22-23

We first fetch 5 contrasts for each subject from the localizer dataset.

.. GENERATED FROM PYTHON SOURCE LINES 23-46

.. code-block:: default

    n_subjects = 2

    contrasts = [
        "sentence reading vs checkerboard",
        "sentence listening",
        "calculation vs sentences",
        "left vs right button press",
        "checkerboard",
    ]
    n_training_contrasts = 4

    brain_data = datasets.fetch_localizer_contrasts(
        contrasts,
        n_subjects=n_subjects,
        get_anats=True,
    )

    source_imgs_paths = brain_data["cmaps"][0 : len(contrasts)]
    target_imgs_paths = brain_data["cmaps"][len(contrasts) : 2 * len(contrasts)]

    source_im = image.load_img(source_imgs_paths)
    target_im = image.load_img(target_imgs_paths)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /usr/local/lib/python3.8/site-packages/nilearn/datasets/func.py:893: UserWarning:

    `legacy_format` will default to `False` in release 0.11. Dataset fetchers will then return pandas dataframes by default instead of recarrays.





.. GENERATED FROM PYTHON SOURCE LINES 47-49

Let's use a resolution of 2000 voxels so that computations
can easily run on a single CPU.

.. GENERATED FROM PYTHON SOURCE LINES 49-72

.. code-block:: default

    SCALE_FACTOR = 3

    source_maps = np.nan_to_num(
        source_im.get_fdata()[::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR]
    )
    target_maps = np.nan_to_num(
        target_im.get_fdata()[::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR]
    )

    segmentation_fine = np.logical_not(np.isnan(source_im.get_fdata()[:, :, :, 0]))
    segmentation_coarse = segmentation_fine[
        ::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR
    ]
    coordinates = np.array(np.nonzero(segmentation_coarse)).T

    source_features = source_maps[
        coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]
    ].T
    target_features = target_maps[
        coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]
    ].T
    source_features.shape





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    (5, 2258)



.. GENERATED FROM PYTHON SOURCE LINES 73-84

.. code-block:: default

    fig = plt.figure(figsize=(5, 5))

    ax = fig.add_subplot(projection="3d")
    ax.set_title("Voxel coordinates")
    ax.scatter(coordinates[:, 0], coordinates[:, 1], coordinates[:, 2], marker=".")

    ax.view_init(10, 135)
    ax.set_axis_off()
    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/01_brain_alignment/images/sphx_glr_plot_4_aligning_high_res_volumes_001.png
   :alt: Voxel coordinates
   :srcset: /auto_examples/01_brain_alignment/images/sphx_glr_plot_4_aligning_high_res_volumes_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 85-86

We then compute the distance matrix between voxel coordinates.

.. GENERATED FROM PYTHON SOURCE LINES 86-94

.. code-block:: default

    source_geometry_embeddings = lmds.compute_lmds_volume(
        segmentation_coarse
    ).nan_to_num()
    target_geometry_embeddings = source_geometry_embeddings.clone()

    # Show the embedding shape
    print(source_geometry_embeddings.shape)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    torch.Size([2258, 3])




.. GENERATED FROM PYTHON SOURCE LINES 95-97

In order to avoid numerical errors when fitting the mapping, we normalize
both the features and the geometry.

.. GENERATED FROM PYTHON SOURCE LINES 97-111

.. code-block:: default

    source_features_normalized = source_features / np.linalg.norm(
        source_features, axis=1
    ).reshape(-1, 1)
    target_features_normalized = target_features / np.linalg.norm(
        target_features, axis=1
    ).reshape(-1, 1)

    source_embeddings_normalized, source_distance_max = (
        coarse_to_fine.random_normalizing(source_geometry_embeddings)
    )
    target_embeddings_normalized, target_distance_max = (
        coarse_to_fine.random_normalizing(target_geometry_embeddings)
    )








.. GENERATED FROM PYTHON SOURCE LINES 112-113

We now fit the mapping using the sinkhorn solver and 3 BCD iterations.

.. GENERATED FROM PYTHON SOURCE LINES 113-133

.. code-block:: default

    alpha_coarse = 0.5
    rho_coarse = 1
    eps_coarse = 1e-4
    coarse_mapping = FUGW(alpha=alpha_coarse, rho=rho_coarse, eps=eps_coarse)
    coarse_mapping_solver = "mm"
    coarse_mapping_solver_params = {
        "nits_bcd": 5,
        "tol_uot": 1e-10,
    }

    alpha_fine = 0.5
    rho_fine = 1
    eps_fine = 1e-4
    fine_mapping = FUGWSparse(alpha=alpha_fine, rho=rho_fine, eps=eps_fine)
    fine_mapping_solver = "mm"
    fine_mapping_solver_params = {
        "nits_bcd": 3,
        "tol_uot": 1e-10,
    }








.. GENERATED FROM PYTHON SOURCE LINES 134-135

Let's subsample the vertices.

.. GENERATED FROM PYTHON SOURCE LINES 135-146

.. code-block:: default

    source_sample = coarse_to_fine.sample_volume_uniformly(
        segmentation_coarse,
        embeddings=source_geometry_embeddings,
        n_samples=1000,
    )
    target_sample = coarse_to_fine.sample_volume_uniformly(
        segmentation_coarse,
        embeddings=target_geometry_embeddings,
        n_samples=1000,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /usr/local/lib/python3.8/site-packages/sklearn/cluster/_agglomerative.py:282: UserWarning:

    the number of connected components of the connectivity matrix is 3 > 1. Completing it to avoid stopping the tree early.

    /usr/local/lib/python3.8/site-packages/sklearn/cluster/_agglomerative.py:282: UserWarning:

    the number of connected components of the connectivity matrix is 3 > 1. Completing it to avoid stopping the tree early.





.. GENERATED FROM PYTHON SOURCE LINES 147-152

Train both the coarse and the fine mapping.
We set the selection radius to 3mm for both source and target
(don't forget to divide by the distance returned by
`coarse_to_fine.random_normalizing()` so that geometries
and selection radia have the same units).

.. GENERATED FROM PYTHON SOURCE LINES 152-178

.. code-block:: default


    _ = coarse_to_fine.fit(
        # Source and target's features and embeddings
        source_features=source_features_normalized[:n_training_contrasts, :],
        target_features=target_features_normalized[:n_training_contrasts, :],
        source_geometry_embeddings=source_embeddings_normalized,
        target_geometry_embeddings=target_embeddings_normalized,
        # Parametrize step 1 (coarse alignment between source and target)
        source_sample=source_sample,
        target_sample=target_sample,
        coarse_mapping=coarse_mapping,
        coarse_mapping_solver=coarse_mapping_solver,
        coarse_mapping_solver_params=coarse_mapping_solver_params,
        # Parametrize step 2 (selection of pairs of indices present in
        # fine-grained's sparsity mask)
        coarse_pairs_selection_method="topk",
        source_selection_radius=3 / source_distance_max,
        target_selection_radius=3 / target_distance_max,
        # Parametrize step 3 (fine-grained alignment)
        fine_mapping=fine_mapping,
        fine_mapping_solver=fine_mapping_solver,
        fine_mapping_solver_params=fine_mapping_solver_params,
        # Misc
        verbose=True,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [17:44:06] Validation data for feature maps is not provided. Using  dense.py:182
               training data instead.                                               
               Validation data for anatomical kernels is not provided.  dense.py:209
               Using training data instead.                                         


    [17:44:16] BCD step 1/5    FUGW loss:      0.025019675493240356     dense.py:512
               Validation loss:        0.025019675493240356                         


    [17:44:26] BCD step 2/5    FUGW loss:      0.020169807597994804     dense.py:512
               Validation loss:        0.020169807597994804                         


    [17:44:35] BCD step 3/5    FUGW loss:      0.011266662739217281     dense.py:512
               Validation loss:        0.011266662739217281                         


    [17:44:45] BCD step 4/5    FUGW loss:      0.006853275001049042     dense.py:512
               Validation loss:        0.006853275001049042                         


    [17:44:58] BCD step 5/5    FUGW loss:      0.005719500593841076     dense.py:512
               Validation loss:        0.005719500593841076                         
    [17:44:59] Validation data for feature maps is not provided. Using sparse.py:203
               training data instead.                                               
               Validation data for anatomical kernels is not provided. sparse.py:247
               Using training data instead.                                         


    [17:45:40] BCD step 1/3    FUGW loss:      0.009396675042808056    sparse.py:574


    [17:46:20] BCD step 2/3    FUGW loss:      0.006626536138355732    sparse.py:574


    [17:47:00] BCD step 3/3    FUGW loss:      0.005600947421044111    sparse.py:574




.. GENERATED FROM PYTHON SOURCE LINES 179-181

Let's plot the probability map of target voxels being matched with
the 300th source voxel.

.. GENERATED FROM PYTHON SOURCE LINES 181-222

.. code-block:: default

    pi = fine_mapping.pi
    vertex_index = 300
    one_hot = np.zeros(source_features.shape[1])
    one_hot[vertex_index] = 1.0
    probability_map = fine_mapping.inverse_transform(one_hot)

    fig = plt.figure(figsize=(7, 5))

    ax = fig.add_subplot(projection="3d")
    ax.set_title(
        "Probability map of target voxels\n"
        f"being matched with source voxel {vertex_index}"
    )

    s = ax.scatter(
        coordinates[:, 0],
        coordinates[:, 1],
        coordinates[:, 2],
        marker="o",
        c=probability_map,
        alpha=0.75,
        cmap="Reds",
    )

    ax.text(
        coordinates[vertex_index, 0],
        coordinates[vertex_index, 1],
        coordinates[vertex_index, 2] - 2,
        "x Source voxel",
        color="black",
        size=12,
    )

    colorbar = fig.colorbar(s, ax=ax, alpha=1)
    colorbar.ax.set_position([0.9, 0.15, 0.03, 0.7])

    ax.view_init(10, 135, 2)
    ax.set_axis_off()
    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/01_brain_alignment/images/sphx_glr_plot_4_aligning_high_res_volumes_002.png
   :alt: Probability map of target voxels being matched with source voxel 300
   :srcset: /auto_examples/01_brain_alignment/images/sphx_glr_plot_4_aligning_high_res_volumes_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 223-224

We can now align test contrasts using the fitted fine mapping.

.. GENERATED FROM PYTHON SOURCE LINES 224-230

.. code-block:: default

    contrast_index = -1
    predicted_target_features = fine_mapping.transform(
        source_features[contrast_index, :]
    )
    predicted_target_features.shape





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    (2258,)



.. GENERATED FROM PYTHON SOURCE LINES 231-232

Let's compare the Pearson correlation between source and target features.

.. GENERATED FROM PYTHON SOURCE LINES 232-246

.. code-block:: default

    corr_pre_mapping = np.corrcoef(
        source_features[contrast_index, :], target_features[contrast_index, :]
    )[0, 1]
    corr_post_mapping = np.corrcoef(
        predicted_target_features, target_features[contrast_index, :]
    )[0, 1]
    print(f"Pearson Correlation pre-mapping: {corr_pre_mapping:.2f}")
    print(f"Pearson Correlation post-mapping: {corr_post_mapping:.2f}")
    print(
        "Relative improvement:"
        f" {(corr_post_mapping - corr_pre_mapping) / corr_pre_mapping *100 :.2f} %"
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Pearson Correlation pre-mapping: 0.38
    Pearson Correlation post-mapping: 0.49
    Relative improvement: 29.34 %




.. GENERATED FROM PYTHON SOURCE LINES 247-248

Let's plot the transporting feature maps of the test set.

.. GENERATED FROM PYTHON SOURCE LINES 248-301

.. code-block:: default

    fig = plt.figure(figsize=(12, 4))
    fig.suptitle("Transporting feature maps of the test set")

    ax = fig.add_subplot(1, 3, 1, projection="3d")
    s = ax.scatter(
        coordinates[:, 0],
        coordinates[:, 1],
        coordinates[:, 2],
        marker="o",
        c=source_features_normalized[-1, :],
        cmap="coolwarm",
        norm=colors.CenteredNorm(),
    )
    ax.view_init(10, 135, 2)
    ax.set_title("Source features")
    ax.set_axis_off()

    ax = fig.add_subplot(1, 3, 2, projection="3d")
    ax.scatter(
        coordinates[:, 0],
        coordinates[:, 1],
        coordinates[:, 2],
        marker="o",
        c=predicted_target_features,
        cmap="coolwarm",
        norm=colors.CenteredNorm(),
    )
    ax.view_init(10, 135, 2)
    ax.set_title("Predicted target features")
    ax.set_axis_off()

    ax = fig.add_subplot(1, 3, 3, projection="3d")
    ax.scatter(
        coordinates[:, 0],
        coordinates[:, 1],
        coordinates[:, 2],
        marker="o",
        c=target_features_normalized[-1, :],
        cmap="coolwarm",
        norm=colors.CenteredNorm(),
    )
    ax.view_init(10, 135, 2)
    ax.set_title("Actual target features")
    ax.set_axis_off()

    ax = fig.add_subplot(1, 1, 1)
    ax.set_axis_off()
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="1%")
    fig.colorbar(s, cax=cax)

    plt.tight_layout()
    plt.show()



.. image-sg:: /auto_examples/01_brain_alignment/images/sphx_glr_plot_4_aligning_high_res_volumes_003.png
   :alt: Transporting feature maps of the test set, Source features, Predicted target features, Actual target features
   :srcset: /auto_examples/01_brain_alignment/images/sphx_glr_plot_4_aligning_high_res_volumes_003.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  58.027 seconds)

**Estimated memory usage:**  8 MB


.. _sphx_glr_download_auto_examples_01_brain_alignment_plot_4_aligning_high_res_volumes.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_4_aligning_high_res_volumes.py <plot_4_aligning_high_res_volumes.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_4_aligning_high_res_volumes.ipynb <plot_4_aligning_high_res_volumes.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
