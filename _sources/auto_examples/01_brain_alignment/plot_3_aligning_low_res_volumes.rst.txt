
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/01_brain_alignment/plot_3_aligning_low_res_volumes.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_01_brain_alignment_plot_3_aligning_low_res_volumes.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_01_brain_alignment_plot_3_aligning_low_res_volumes.py:


===============================================================
Low-resolution volume alignment of 2 individuals with fMRI data
===============================================================

In this example, we align 2 low-resolution brain volumes
using 4 fMRI feature maps (z-score contrast maps).

.. GENERATED FROM PYTHON SOURCE LINES 10-21

.. code-block:: default


    import numpy as np
    import matplotlib.colors as colors
    import matplotlib.pyplot as plt

    from mpl_toolkits.axes_grid1 import make_axes_locatable
    from nilearn import datasets, image
    from scipy.spatial import distance_matrix

    from fugw.mappings import FUGW








.. GENERATED FROM PYTHON SOURCE LINES 23-24

We first fetch 5 contrasts for each subject from the localizer dataset.

.. GENERATED FROM PYTHON SOURCE LINES 24-47

.. code-block:: default

    n_subjects = 2

    contrasts = [
        "sentence reading vs checkerboard",
        "sentence listening",
        "calculation vs sentences",
        "left vs right button press",
        "checkerboard",
    ]
    n_training_contrasts = 4

    brain_data = datasets.fetch_localizer_contrasts(
        contrasts,
        n_subjects=n_subjects,
        get_anats=True,
    )

    source_imgs_paths = brain_data["cmaps"][0 : len(contrasts)]
    target_imgs_paths = brain_data["cmaps"][len(contrasts) : 2 * len(contrasts)]

    source_im = image.load_img(source_imgs_paths)
    target_im = image.load_img(target_imgs_paths)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /usr/local/lib/python3.8/site-packages/nilearn/datasets/func.py:893: UserWarning:

    `legacy_format` will default to `False` in release 0.11. Dataset fetchers will then return pandas dataframes by default instead of recarrays.





.. GENERATED FROM PYTHON SOURCE LINES 48-50

We greatly downsample all image to reduce the computational cost
so that this example will run on a CPU.

.. GENERATED FROM PYTHON SOURCE LINES 50-65

.. code-block:: default

    SCALE_FACTOR = 5

    source_maps = np.nan_to_num(
        source_im.get_fdata()[::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR]
    )
    target_maps = np.nan_to_num(
        target_im.get_fdata()[::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR]
    )

    segmentation_fine = np.logical_not(np.isnan(source_im.get_fdata()[:, :, :, 0]))
    segmentation_coarse = segmentation_fine[
        ::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR
    ]
    coordinates = np.array(np.nonzero(segmentation_coarse)).T








.. GENERATED FROM PYTHON SOURCE LINES 66-76

.. code-block:: default

    fig = plt.figure(figsize=(5, 5))

    ax = fig.add_subplot(projection="3d")
    ax.set_title("Anatomical coordinates of voxels")
    ax.scatter(coordinates[:, 0], coordinates[:, 1], coordinates[:, 2], marker="o")

    ax.view_init(10, 135)
    ax.set_axis_off()
    plt.show()




.. image-sg:: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_001.png
   :alt: Anatomical coordinates of voxels
   :srcset: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 77-79

Eventually, we extract the features at each voxel
and end up with roughly 500 voxels.

.. GENERATED FROM PYTHON SOURCE LINES 79-89

.. code-block:: default


    source_features = source_maps[
        coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]
    ].T
    target_features = target_maps[
        coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]
    ].T
    source_features.shape






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    (5, 484)



.. GENERATED FROM PYTHON SOURCE LINES 90-91

We then compute the distance matrix between voxel coordinates.

.. GENERATED FROM PYTHON SOURCE LINES 91-107

.. code-block:: default

    source_geometry = distance_matrix(coordinates, coordinates)
    target_geometry = source_geometry.copy()

    fig = plt.figure(figsize=(5, 5))

    ax = fig.add_subplot(111)
    ax.set_title("Distance matrix between voxels")
    im = ax.imshow(source_geometry)

    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="3%", pad="2%")
    fig.colorbar(im, cax=cax, label="mm")

    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_002.png
   :alt: Distance matrix between voxels
   :srcset: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 108-154

.. code-block:: default

    vertex_index = 4
    fig = plt.figure(figsize=(7, 5))

    ax = fig.add_subplot(111, projection="3d")
    ax.set_title(f"Distance to source voxel {vertex_index}")

    # Plot brain geometry
    im = ax.scatter(
        coordinates[1:, 0],
        coordinates[1:, 1],
        coordinates[1:, 2],
        marker=".",
        c=source_geometry[0, 1:],
    )

    # Add source point label
    ax.scatter(
        coordinates[vertex_index, 0],
        coordinates[vertex_index, 1],
        coordinates[vertex_index, 2],
        marker="o",
        c="black",
    )
    ax.text(
        coordinates[vertex_index, 0],
        coordinates[vertex_index, 1],
        coordinates[vertex_index, 2] - 2,
        "Source point",
        size=12,
        color="black",
    )

    # Add colorbar
    colorbar = fig.colorbar(
        im,
        ax=ax,
        label="mm",
    )
    colorbar.ax.set_position([0.9, 0.15, 0.03, 0.7])

    ax.view_init(10, 135)
    ax.set_axis_off()

    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_003.png
   :alt: Distance to source voxel 4
   :srcset: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 155-157

In order to avoid numerical errors when fitting the mapping, we normalize
both the features and the geometry.

.. GENERATED FROM PYTHON SOURCE LINES 157-166

.. code-block:: default

    source_features_normalized = source_features / np.linalg.norm(
        source_features, axis=1
    ).reshape(-1, 1)
    target_features_normalized = target_features / np.linalg.norm(
        target_features, axis=1
    ).reshape(-1, 1)
    source_geometry_normalized = source_geometry / np.max(source_geometry)
    target_geometry_normalized = target_geometry / np.max(target_geometry)








.. GENERATED FROM PYTHON SOURCE LINES 167-168

We now fit the mapping using the sinkhorn solver and 3 BCD iterations.

.. GENERATED FROM PYTHON SOURCE LINES 168-181

.. code-block:: default

    mapping = FUGW(alpha=0.5, rho=1, eps=1e-4)
    _ = mapping.fit(
        source_features_normalized[:n_training_contrasts],
        target_features_normalized[:n_training_contrasts],
        source_geometry=source_geometry_normalized,
        target_geometry=target_geometry_normalized,
        solver="sinkhorn",
        solver_params={
            "nits_bcd": 4,
        },
        verbose=True,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [20:27:04] Validation data for feature maps is not provided. Using  dense.py:199
               training data instead.                                               
               Validation data for anatomical kernels is not provided.  dense.py:226
               Using training data instead.                                         


    [20:27:16] BCD step 1/4    FUGW loss:      0.025816770270466805     dense.py:521
               Validation loss:        0.025816770270466805                         


    [20:27:35] BCD step 2/4    FUGW loss:      0.009245545603334904     dense.py:521
               Validation loss:        0.009245545603334904                         


    [20:27:54] BCD step 3/4    FUGW loss:      0.007908135652542114     dense.py:521
               Validation loss:        0.007908135652542114                         


    [20:28:12] BCD step 4/4    FUGW loss:      0.007553239353001118     dense.py:521
               Validation loss:        0.007553239353001118                         




.. GENERATED FROM PYTHON SOURCE LINES 182-184

Let's plot the probability map of target voxels being matched with
the 4th source voxel.

.. GENERATED FROM PYTHON SOURCE LINES 184-215

.. code-block:: default

    pi = mapping.pi
    probability_map = pi[vertex_index, :] / np.sqrt(
        np.linalg.norm(pi[vertex_index, :])
    )

    fig = plt.figure(figsize=(5, 5))

    ax = fig.add_subplot(projection="3d")
    ax.set_title(
        "Probability map of target voxels\n"
        f"being matched with source voxel {vertex_index}"
    )

    s = ax.scatter(
        coordinates[:, 0],
        coordinates[:, 1],
        coordinates[:, 2],
        marker=".",
        c=probability_map,
        cmap="viridis",
        alpha=0.75,
    )

    colorbar = fig.colorbar(s, ax=ax)
    colorbar.ax.set_position([0.9, 0.15, 0.03, 0.7])

    ax.view_init(10, 135, 2)
    ax.set_axis_off()
    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_004.png
   :alt: Probability map of target voxels being matched with source voxel 4
   :srcset: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 216-217

We can now align test contrasts using the fitted mapping.

.. GENERATED FROM PYTHON SOURCE LINES 217-223

.. code-block:: default

    contrast_index = -1
    predicted_target_features = mapping.transform(
        source_features[contrast_index, :]
    )
    predicted_target_features.shape





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    (484,)



.. GENERATED FROM PYTHON SOURCE LINES 224-225

Let's compare the Pearson correlation between source and target features.

.. GENERATED FROM PYTHON SOURCE LINES 225-239

.. code-block:: default

    corr_pre_mapping = np.corrcoef(
        source_features[contrast_index, :], target_features[contrast_index, :]
    )[0, 1]
    corr_post_mapping = np.corrcoef(
        predicted_target_features, target_features[contrast_index, :]
    )[0, 1]
    print(f"Pearson Correlation pre-mapping: {corr_pre_mapping:.2f}")
    print(f"Pearson Correlation post-mapping: {corr_post_mapping:.2f}")
    print(
        "Relative improvement:"
        f" {(corr_post_mapping - corr_pre_mapping) / corr_pre_mapping *100 :.2f} %"
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Pearson Correlation pre-mapping: 0.28
    Pearson Correlation post-mapping: 0.37
    Relative improvement: 30.16 %




.. GENERATED FROM PYTHON SOURCE LINES 240-241

Let's plot the transporting feature maps of the test set.

.. GENERATED FROM PYTHON SOURCE LINES 241-298

.. code-block:: default

    fig = plt.figure(figsize=(12, 4))

    fig.suptitle("Transporting feature maps of the test set")

    ax = fig.add_subplot(1, 3, 1, projection="3d")
    s = ax.scatter(
        coordinates[:, 0],
        coordinates[:, 1],
        coordinates[:, 2],
        marker="o",
        c=source_features_normalized[-1, :],
        cmap="coolwarm",
        norm=colors.CenteredNorm(),
    )

    ax.view_init(10, 135, 2)
    ax.set_title("Source features")
    ax.set_axis_off()

    ax = fig.add_subplot(1, 3, 2, projection="3d")
    ax.scatter(
        coordinates[:, 0],
        coordinates[:, 1],
        coordinates[:, 2],
        marker="o",
        c=predicted_target_features,
        cmap="coolwarm",
        norm=colors.CenteredNorm(),
    )

    ax.view_init(10, 135, 2)
    ax.set_title("Predicted target features")
    ax.set_axis_off()

    ax = fig.add_subplot(1, 3, 3, projection="3d")
    ax.scatter(
        coordinates[:, 0],
        coordinates[:, 1],
        coordinates[:, 2],
        marker="o",
        c=target_features_normalized[-1, :],
        cmap="coolwarm",
        norm=colors.CenteredNorm(),
    )

    ax.view_init(10, 135, 2)
    ax.set_title("Actual target features")
    ax.set_axis_off()

    ax = fig.add_subplot(1, 1, 1)
    ax.set_axis_off()
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="1%")
    fig.colorbar(s, cax=cax)

    plt.tight_layout()
    plt.show()



.. image-sg:: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_005.png
   :alt: Transporting feature maps of the test set, Source features, Predicted target features, Actual target features
   :srcset: /auto_examples/01_brain_alignment/images/sphx_glr_plot_3_aligning_low_res_volumes_005.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 13.027 seconds)

**Estimated memory usage:**  8 MB


.. _sphx_glr_download_auto_examples_01_brain_alignment_plot_3_aligning_low_res_volumes.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_3_aligning_low_res_volumes.py <plot_3_aligning_low_res_volumes.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_3_aligning_low_res_volumes.ipynb <plot_3_aligning_low_res_volumes.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
