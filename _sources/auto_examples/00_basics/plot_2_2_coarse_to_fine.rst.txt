
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/00_basics/plot_2_2_coarse_to_fine.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_00_basics_plot_2_2_coarse_to_fine.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_00_basics_plot_2_2_coarse_to_fine.py:


Transport distributions using sparse solvers
============================================

In this example, we sample 2 toy distributions and compute
a sparse fugw alignment between them.
Sparse alignments are typically used when both aligned distributions
have more than 10k points.

.. GENERATED FROM PYTHON SOURCE LINES 11-21

.. code-block:: default


    import matplotlib.pyplot as plt
    import torch

    from fugw.mappings import FUGW, FUGWSparse
    from fugw.scripts import coarse_to_fine
    from fugw.utils import init_mock_distribution
    from matplotlib.collections import LineCollection
    from scipy.sparse import coo_matrix








.. GENERATED FROM PYTHON SOURCE LINES 23-32

.. code-block:: default

    torch.manual_seed(13)

    n_points_source = 300
    n_samples_source = 100
    n_points_target = 300
    n_samples_target = 100
    n_features_train = 2
    n_features_test = 2








.. GENERATED FROM PYTHON SOURCE LINES 33-34

Let us generate random training data for the source and target distributions

.. GENERATED FROM PYTHON SOURCE LINES 34-41

.. code-block:: default

    _, source_features_train, _, source_embeddings = init_mock_distribution(
        n_features_train, n_points_source
    )
    _, target_features_train, _, target_embeddings = init_mock_distribution(
        n_features_train, n_points_target
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /usr/local/lib/python3.8/site-packages/torch/distributions/wishart.py:250: UserWarning:

    Singular sample detected.





.. GENERATED FROM PYTHON SOURCE LINES 42-43

We can visualize the generated features:

.. GENERATED FROM PYTHON SOURCE LINES 43-52

.. code-block:: default

    fig = plt.figure(figsize=(4, 4))
    ax = fig.add_subplot()
    ax.set_title("Source and target features")
    ax.set_aspect("equal", "datalim")
    ax.scatter(source_features_train[0], source_features_train[1], label="Source")
    ax.scatter(target_features_train[0], target_features_train[1], label="Target")
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_001.png
   :alt: Source and target features
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 53-55

Do not forget to normalize features and embeddings
before fitting the models.

.. GENERATED FROM PYTHON SOURCE LINES 55-70

.. code-block:: default


    source_features_train_normalized = source_features_train / torch.linalg.norm(
        source_features_train, dim=1
    ).reshape(-1, 1)
    target_features_train_normalized = target_features_train / torch.linalg.norm(
        target_features_train, dim=1
    ).reshape(-1, 1)

    source_embeddings_normalized, source_d_max = coarse_to_fine.random_normalizing(
        source_embeddings
    )
    target_embeddings_normalized, target_d_max = coarse_to_fine.random_normalizing(
        target_embeddings
    )








.. GENERATED FROM PYTHON SOURCE LINES 71-73

Let us define the coarse and fine-grained optimization problems to solve.
We also specify which solver to use at each of the 2 steps:

.. GENERATED FROM PYTHON SOURCE LINES 73-85

.. code-block:: default

    coarse_mapping = FUGW(alpha=0.5, eps=1e-4)
    coarse_mapping_solver = "mm"
    coarse_mapping_solver_params = {
        "tol_uot": 1e-10,
    }

    fine_mapping = FUGWSparse(alpha=0.5, eps=1e-4)
    fine_mapping_solver = "mm"
    fine_mapping_solver_params = {
        "tol_uot": 1e-10,
    }








.. GENERATED FROM PYTHON SOURCE LINES 86-94

Now, let us fit both the coarse and fine-grained mappings.
The coarse mapping is fitted on a limited number
of points from the source and target distributions,
which we sample randomly in this example.
You should carefully set the source and target ``selection_radius``
as they will greatly affect the sparsity of the computed mappings.
They should usally be set using domain knowledge related to the distributions
you are trying to align.

.. GENERATED FROM PYTHON SOURCE LINES 94-124

.. code-block:: default


    # Sub-sample source and target distributions
    source_sample = torch.randperm(n_points_source)[:n_samples_source]
    target_sample = torch.randperm(n_points_target)[:n_samples_target]

    coarse_to_fine.fit(
        # Source and target's features and embeddings
        source_features=source_features_train_normalized,
        target_features=target_features_train_normalized,
        source_geometry_embeddings=source_embeddings_normalized,
        target_geometry_embeddings=target_embeddings_normalized,
        # Parametrize step 1 (coarse alignment between source and target)
        source_sample=source_sample,
        target_sample=target_sample,
        coarse_mapping=coarse_mapping,
        coarse_mapping_solver=coarse_mapping_solver,
        coarse_mapping_solver_params=coarse_mapping_solver_params,
        # Parametrize step 2 (selection of pairs of indices present in
        # fine-grained's sparsity mask)
        coarse_pairs_selection_method="topk",
        source_selection_radius=0.5 / source_d_max,
        target_selection_radius=0.5 / target_d_max,
        # Parametrize step 3 (fine-grained alignment)
        fine_mapping=fine_mapping,
        fine_mapping_solver=fine_mapping_solver,
        fine_mapping_solver_params=fine_mapping_solver_params,
        # Misc
        verbose=True,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none



    [14:44:10] BCD step 1/10   FUGW loss:      0.03198949992656708      dense.py:360
               (base)      0.032095134258270264 (entropic)                          


               BCD step 2/10   FUGW loss:      0.027364276349544525     dense.py:360
               (base)     0.027612881734967232 (entropic)                           


               BCD step 3/10   FUGW loss:      0.017961936071515083     dense.py:360
               (base)     0.01844286173582077 (entropic)                            


    [14:44:11] BCD step 4/10   FUGW loss:      0.015194778330624104     dense.py:360
               (base)     0.015796463936567307 (entropic)                           


               BCD step 5/10   FUGW loss:      0.014496020041406155     dense.py:360
               (base)     0.015153813175857067 (entropic)                           


               BCD step 6/10   FUGW loss:      0.014186171814799309     dense.py:360
               (base)     0.014875920489430428 (entropic)                           


    [14:44:12] BCD step 7/10   FUGW loss:      0.014005331322550774     dense.py:360
               (base)     0.01471529621630907 (entropic)                            


    [14:44:13] BCD step 8/10   FUGW loss:      0.013867946341633797     dense.py:360
               (base)     0.014592503197491169 (entropic)                           


    [14:44:14] BCD step 9/10   FUGW loss:      0.013740603812038898     dense.py:360
               (base)     0.014477620832622051 (entropic)                           


    [14:44:15] BCD step 10/10  FUGW loss:      0.013632165268063545     dense.py:360
               (base)     0.014380687847733498 (entropic)                           
    /github/workspace/src/fugw/utils.py:60: UserWarning:

    Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)



    [14:44:18] BCD step 1/10   FUGW loss:      0.020308256149291992    sparse.py:478
               (base)     0.020477615296840668 (entropic)                           


    [14:44:22] BCD step 2/10   FUGW loss:      0.013988880440592766    sparse.py:478
               (base)     0.014400288462638855 (entropic)                           


    [14:44:25] BCD step 3/10   FUGW loss:      0.01208634115755558     sparse.py:478
               (base)      0.012644429691135883 (entropic)                          


    [14:44:28] BCD step 4/10   FUGW loss:      0.011344446800649166    sparse.py:478
               (base)     0.011991022154688835 (entropic)                           


    [14:44:31] BCD step 5/10   FUGW loss:      0.010971869342029095    sparse.py:478
               (base)     0.011676927097141743 (entropic)                           


    [14:44:35] BCD step 6/10   FUGW loss:      0.010754159651696682    sparse.py:478
               (base)     0.01150030642747879 (entropic)                            


    [14:44:39] BCD step 7/10   FUGW loss:      0.010611843317747116    sparse.py:478
               (base)     0.011388429440557957 (entropic)                           


    [14:44:44] BCD step 8/10   FUGW loss:      0.010510009713470936    sparse.py:478
               (base)     0.011310222558677197 (entropic)                           


    [14:44:49] BCD step 9/10   FUGW loss:      0.01043227780610323     sparse.py:478
               (base)      0.011251525953412056 (entropic)                          


    [14:44:56] BCD step 10/10  FUGW loss:      0.01037062332034111     sparse.py:478
               (base)      0.011205591261386871 (entropic)                          

    (tensor([ 52, 229, 140, 249, 186, 210, 131, 128, 209, 227,   6,  75,  71, 217,
            164, 291,  58, 109, 116, 118,  66, 206, 189, 212,  15, 286,  14, 268,
             64, 127,  70,  25,  60, 106, 142, 185,  11, 136,  31, 226, 284, 287,
            276,   1,  33, 120, 273, 182,  39, 266,  88,  82, 223,  96, 101, 256,
             62, 264, 211,  48, 219, 283,  36, 280,  76,  12, 238,  44,  80,  50,
             38, 244,  34, 122, 148,  99, 113,  43,  49,  92, 170, 133, 107, 296,
            111,   3, 199, 247, 299, 257, 258,  85,  26, 259,   5, 184,  19, 263,
            298, 196]), tensor([  1,  63,  58,  35,   2, 153, 188, 136, 161,  45, 178, 120, 297,  75,
            134, 226, 183, 295, 126,  54,  11, 108, 124, 210, 127, 203,  42, 106,
            260, 193, 133, 123, 224,  80,  38,  46, 100,  67, 184, 206,  68,  97,
            207,  77, 245, 116,  25, 199, 288,   6,  17, 290, 180, 117, 280, 172,
            235, 227,  22,  94, 221, 162,  59, 102, 132, 249,  78, 144, 212, 122,
            264, 243,  20, 112, 289, 187,  12, 233,  19, 151, 196,  29, 142,  70,
             36, 211, 256, 217, 113, 269, 104, 248,  66,   9, 140, 101, 105,  81,
            267, 154]))



.. GENERATED FROM PYTHON SOURCE LINES 125-127

Both the coarse and fine-grained transport plans can be accessed
after the models have been fitted

.. GENERATED FROM PYTHON SOURCE LINES 127-133

.. code-block:: default

    print(f"Coarse transport plan's total mass: {coarse_mapping.pi.sum():.5f}")
    print(
        "Fine-grained transport plan's total mass:"
        f" {torch.sparse.sum(fine_mapping.pi):.5f}"
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Coarse transport plan's total mass: 0.99738
    Fine-grained transport plan's total mass: 0.99811




.. GENERATED FROM PYTHON SOURCE LINES 134-136

Here is the evolution of the FUGW loss during training
of the coarse mapping, with and without the entropic term:

.. GENERATED FROM PYTHON SOURCE LINES 136-150

.. code-block:: default


    fig, ax = plt.subplots(figsize=(4, 4))
    ax.set_title("Coarse mapping training loss")
    ax.set_ylabel("Loss")
    ax.set_xlabel("BCD step")
    ax.plot(coarse_mapping.loss_steps, coarse_mapping.loss, label="FUGW loss")
    ax.plot(
        coarse_mapping.loss_steps,
        coarse_mapping.loss_entropic,
        label="FUGW entropic loss",
    )
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_002.png
   :alt: Coarse mapping training loss
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 151-152

And here is that of the fine-grained mapping:

.. GENERATED FROM PYTHON SOURCE LINES 152-166

.. code-block:: default


    fig, ax = plt.subplots(figsize=(4, 4))
    ax.set_title("Fine-grained mapping training loss")
    ax.set_ylabel("Loss")
    ax.set_xlabel("BCD step")
    ax.plot(fine_mapping.loss_steps, fine_mapping.loss, label="FUGW loss")
    ax.plot(
        fine_mapping.loss_steps,
        fine_mapping.loss_entropic,
        label="FUGW entropic loss",
    )
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_003.png
   :alt: Fine-grained mapping training loss
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 167-172

In this example, the computed sparse transport plan is not very sparse:
it stores about 60% of what the equivalent dense transport plan
would store.
When aligning distributions with a high number of points,
we usually want to keep this number much smaller.

.. GENERATED FROM PYTHON SOURCE LINES 172-178

.. code-block:: default


    sparsity_ratio = (
        100 * fine_mapping.pi.values().shape[0] / fine_mapping.pi.shape.numel()
    )
    print(f"Ratio of non-null coefficients: {sparsity_ratio:.2f}%")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Ratio of non-null coefficients: 86.10%




.. GENERATED FROM PYTHON SOURCE LINES 179-182

We can also have a look at the sparsity mask of the
fine-grained transport plan. In this particular example,
we don't expect it to show a particularly meaningful structure.

.. GENERATED FROM PYTHON SOURCE LINES 182-198

.. code-block:: default

    indices = fine_mapping.pi.indices()
    fine_mapping_as_scipy_coo = coo_matrix(
        (
            fine_mapping.pi.values(),
            (indices[0], indices[1]),
        ),
        shape=fine_mapping.pi.size(),
    )

    fig, ax = plt.subplots(figsize=(5, 5))
    ax.set_title("Sparsity mask of fine-grained mapping")
    ax.set_ylabel("Source vertices")
    ax.set_xlabel("Target vertices")
    plt.spy(fine_mapping_as_scipy_coo, precision="present", markersize=0.3)
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_004.png
   :alt: Sparsity mask of fine-grained mapping
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 199-201

We can observe the computed mappings between source
and target points in the feature space.

.. GENERATED FROM PYTHON SOURCE LINES 201-234

.. code-block:: default

    pi = fine_mapping.pi.to_dense()
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot()
    ax.set_aspect("equal", "datalim")
    ax.set_title("Mapping\ndisplayed in feature space")

    # Draw lines between matched points
    indices = torch.cartesian_prod(
        torch.arange(n_points_source), torch.arange(n_points_target)
    )
    segments = torch.stack(
        [
            source_features_train[:, indices[:, 0]],
            target_features_train[:, indices[:, 1]],
        ]
    ).permute(2, 0, 1)
    pi_normalized = pi / pi.sum(dim=1).reshape(-1, 1)
    line_segments = LineCollection(
        segments,
        alpha=pi_normalized.flatten().nan_to_num(),
        colors="black",
        lw=1,
        zorder=1,
    )
    ax.add_collection(line_segments)

    # Draw distributions
    ax.scatter(source_features_train[0], source_features_train[1], label="Source")
    ax.scatter(target_features_train[0], target_features_train[1], label="Target")

    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_005.png
   :alt: Mapping displayed in feature space
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_005.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 235-237

Finally, the fitted fine-grained model can transport unseen data
between source and target

.. GENERATED FROM PYTHON SOURCE LINES 237-242

.. code-block:: default

    source_features_test = torch.rand(n_features_test, n_points_source)
    target_features_test = torch.rand(n_features_test, n_points_target)
    transformed_data = fine_mapping.transform(source_features_test)
    transformed_data.shape





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    torch.Size([2, 300])



.. GENERATED FROM PYTHON SOURCE LINES 243-244

.. code-block:: default

    assert transformed_data.shape == target_features_test.shape








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  54.436 seconds)

**Estimated memory usage:**  151 MB


.. _sphx_glr_download_auto_examples_00_basics_plot_2_2_coarse_to_fine.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_2_2_coarse_to_fine.py <plot_2_2_coarse_to_fine.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_2_2_coarse_to_fine.ipynb <plot_2_2_coarse_to_fine.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
