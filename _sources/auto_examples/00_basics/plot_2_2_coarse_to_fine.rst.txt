
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/00_basics/plot_2_2_coarse_to_fine.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_00_basics_plot_2_2_coarse_to_fine.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_00_basics_plot_2_2_coarse_to_fine.py:


Transport distributions using sparse solvers
============================================

In this example, we sample 2 toy distributions and compute
a sparse fugw alignment between them.
Sparse alignments are typically used when both aligned distributions
have more than 10k points.

.. GENERATED FROM PYTHON SOURCE LINES 11-22

.. code-block:: default


    import matplotlib.pyplot as plt
    import numpy as np
    import torch

    from fugw.mappings import FUGW, FUGWSparse
    from fugw.scripts import coarse_to_fine
    from fugw.utils import _init_mock_distribution
    from matplotlib.collections import LineCollection
    from scipy.sparse import coo_matrix








.. GENERATED FROM PYTHON SOURCE LINES 24-33

.. code-block:: default

    torch.manual_seed(13)

    n_points_source = 300
    n_samples_source = 100
    n_points_target = 300
    n_samples_target = 100
    n_features_train = 2
    n_features_test = 2








.. GENERATED FROM PYTHON SOURCE LINES 34-35

Let us generate random training data for the source and target distributions

.. GENERATED FROM PYTHON SOURCE LINES 35-42

.. code-block:: default

    _, source_features_train, _, source_embeddings = _init_mock_distribution(
        n_features_train, n_points_source
    )
    _, target_features_train, _, target_embeddings = _init_mock_distribution(
        n_features_train, n_points_target
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /usr/local/lib/python3.8/site-packages/torch/distributions/wishart.py:253: UserWarning:

    Singular sample detected.





.. GENERATED FROM PYTHON SOURCE LINES 43-44

We can visualize the generated features:

.. GENERATED FROM PYTHON SOURCE LINES 44-53

.. code-block:: default

    fig = plt.figure(figsize=(4, 4))
    ax = fig.add_subplot()
    ax.set_title("Source and target features")
    ax.set_aspect("equal", "datalim")
    ax.scatter(source_features_train[0], source_features_train[1], label="Source")
    ax.scatter(target_features_train[0], target_features_train[1], label="Target")
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_001.png
   :alt: Source and target features
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 54-56

Do not forget to normalize features and embeddings
before fitting the models.

.. GENERATED FROM PYTHON SOURCE LINES 56-71

.. code-block:: default


    source_features_train_normalized = source_features_train / torch.linalg.norm(
        source_features_train, dim=1
    ).reshape(-1, 1)
    target_features_train_normalized = target_features_train / torch.linalg.norm(
        target_features_train, dim=1
    ).reshape(-1, 1)

    source_embeddings_normalized, source_d_max = coarse_to_fine.random_normalizing(
        source_embeddings
    )
    target_embeddings_normalized, target_d_max = coarse_to_fine.random_normalizing(
        target_embeddings
    )








.. GENERATED FROM PYTHON SOURCE LINES 72-74

Let us define the coarse and fine-grained optimization problems to solve.
We also specify which solver to use at each of the 2 steps:

.. GENERATED FROM PYTHON SOURCE LINES 74-92

.. code-block:: default

    alpha_coarse = 0.5
    rho_coarse = 1
    eps_coarse = 1e-4
    coarse_mapping = FUGW(alpha=alpha_coarse, rho=rho_coarse, eps=eps_coarse)
    coarse_mapping_solver = "mm"
    coarse_mapping_solver_params = {
        "tol_uot": 1e-10,
    }

    alpha_fine = 0.5
    rho_fine = 1
    eps_fine = 1e-4
    fine_mapping = FUGWSparse(alpha=alpha_fine, rho=rho_fine, eps=eps_fine)
    fine_mapping_solver = "mm"
    fine_mapping_solver_params = {
        "tol_uot": 1e-10,
    }








.. GENERATED FROM PYTHON SOURCE LINES 93-101

Now, let us fit both the coarse and fine-grained mappings.
The coarse mapping is fitted on a limited number
of points from the source and target distributions,
which we sample randomly in this example.
You should carefully set the source and target ``selection_radius``
as they will greatly affect the sparsity of the computed mappings.
They should usually be set using domain knowledge related to the
distributions you are trying to align.

.. GENERATED FROM PYTHON SOURCE LINES 101-131

.. code-block:: default


    # Sub-sample source and target distributions
    source_sample = torch.randperm(n_points_source)[:n_samples_source]
    target_sample = torch.randperm(n_points_target)[:n_samples_target]

    _ = coarse_to_fine.fit(
        # Source and target's features and embeddings
        source_features=source_features_train_normalized,
        target_features=target_features_train_normalized,
        source_geometry_embeddings=source_embeddings_normalized,
        target_geometry_embeddings=target_embeddings_normalized,
        # Parametrize step 1 (coarse alignment between source and target)
        source_sample=source_sample,
        target_sample=target_sample,
        coarse_mapping=coarse_mapping,
        coarse_mapping_solver=coarse_mapping_solver,
        coarse_mapping_solver_params=coarse_mapping_solver_params,
        # Parametrize step 2 (selection of pairs of indices present in
        # fine-grained's sparsity mask)
        coarse_pairs_selection_method="topk",
        source_selection_radius=0.5 / source_d_max,
        target_selection_radius=0.5 / target_d_max,
        # Parametrize step 3 (fine-grained alignment)
        fine_mapping=fine_mapping,
        fine_mapping_solver=fine_mapping_solver,
        fine_mapping_solver_params=fine_mapping_solver_params,
        # Misc
        verbose=True,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [20:35:23] Validation data for feature maps is not provided. Using  dense.py:199
               training data instead.                                               
               Validation data for anatomical kernels is not provided.  dense.py:226
               Using training data instead.                                         


               BCD step 1/10   FUGW loss:      0.03209497034549713      dense.py:521
               Validation loss:        0.03209497034549713                          


               BCD step 2/10   FUGW loss:      0.027612194418907166     dense.py:521
               Validation loss:        0.027612194418907166                         


    [20:35:24] BCD step 3/10   FUGW loss:      0.018442397937178612     dense.py:521
               Validation loss:        0.018442397937178612                         


               BCD step 4/10   FUGW loss:      0.015796462073922157     dense.py:521
               Validation loss:        0.015796462073922157                         


               BCD step 5/10   FUGW loss:      0.015153703279793262     dense.py:521
               Validation loss:        0.015153703279793262                         


    [20:35:25] BCD step 6/10   FUGW loss:      0.014875943772494793     dense.py:521
               Validation loss:        0.014875943772494793                         


    [20:35:26] BCD step 7/10   FUGW loss:      0.014715139754116535     dense.py:521
               Validation loss:        0.014715139754116535                         


    [20:35:27] BCD step 8/10   FUGW loss:      0.01459245290607214      dense.py:521
               Validation loss:        0.01459245290607214                          


    [20:35:28] BCD step 9/10   FUGW loss:      0.014477240853011608     dense.py:521
               Validation loss:        0.014477240853011608                         


    [20:35:29] BCD step 10/10  FUGW loss:      0.01438040379434824      dense.py:521
               Validation loss:        0.01438040379434824                          
    /github/workspace/src/fugw/scripts/coarse_to_fine.py:463: UserWarning:

    Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)

               Validation data for feature maps is not provided. Using sparse.py:209
               training data instead.                                               
               Validation data for anatomical kernels is not provided. sparse.py:253
               Using training data instead.                                         


    [20:35:33] BCD step 1/10   FUGW loss:      0.020477116107940674    sparse.py:660


    [20:35:36] BCD step 2/10   FUGW loss:      0.014399956911802292    sparse.py:660


    [20:35:40] BCD step 3/10   FUGW loss:      0.012644489295780659    sparse.py:660


    [20:35:44] BCD step 4/10   FUGW loss:      0.011991250328719616    sparse.py:660


    [20:35:48] BCD step 5/10   FUGW loss:      0.01167681347578764     sparse.py:660


    [20:35:52] BCD step 6/10   FUGW loss:      0.011500151827931404    sparse.py:660


    [20:35:56] BCD step 7/10   FUGW loss:      0.011388338170945644    sparse.py:660


    [20:36:01] BCD step 8/10   FUGW loss:      0.011310356669127941    sparse.py:660


    [20:36:07] BCD step 9/10   FUGW loss:      0.011251559481024742    sparse.py:660


    [20:36:14] BCD step 10/10  FUGW loss:      0.01120560523122549     sparse.py:660




.. GENERATED FROM PYTHON SOURCE LINES 132-134

Both the coarse and fine-grained transport plans can be accessed
after the models have been fitted

.. GENERATED FROM PYTHON SOURCE LINES 134-140

.. code-block:: default

    print(f"Coarse transport plan's total mass: {coarse_mapping.pi.sum():.5f}")
    print(
        "Fine-grained transport plan's total mass:"
        f" {torch.sparse.sum(fine_mapping.pi):.5f}"
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Coarse transport plan's total mass: 0.99738
    Fine-grained transport plan's total mass: 0.99811




.. GENERATED FROM PYTHON SOURCE LINES 141-143

Here is the evolution of the FUGW loss during training
of the coarse mapping, as well as the contribution of each loss term:

.. GENERATED FROM PYTHON SOURCE LINES 143-169

.. code-block:: default


    fig, ax = plt.subplots(figsize=(10, 4))
    ax.set_title("Coarse mapping training loss")
    ax.set_ylabel("Loss")
    ax.set_xlabel("BCD step")
    ax.stackplot(
        coarse_mapping.loss_steps,
        [
            (1 - alpha_coarse) * np.array(coarse_mapping.loss["wasserstein"]),
            alpha_coarse * np.array(coarse_mapping.loss["gromov_wasserstein"]),
            rho_coarse * np.array(coarse_mapping.loss["marginal_constraint_dim1"]),
            rho_coarse * np.array(coarse_mapping.loss["marginal_constraint_dim2"]),
            eps_coarse * np.array(coarse_mapping.loss["regularization"]),
        ],
        labels=[
            "wasserstein",
            "gromov_wasserstein",
            "marginal_constraint_dim1",
            "marginal_constraint_dim2",
            "regularization",
        ],
        alpha=0.8,
    )
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_002.png
   :alt: Coarse mapping training loss
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 170-171

And here is a similar plot for the fine-grained mapping:

.. GENERATED FROM PYTHON SOURCE LINES 171-197

.. code-block:: default


    fig, ax = plt.subplots(figsize=(10, 4))
    ax.set_title("Fine-grained mapping training loss")
    ax.set_ylabel("Loss")
    ax.set_xlabel("BCD step")
    ax.stackplot(
        fine_mapping.loss_steps,
        [
            (1 - alpha_fine) * np.array(fine_mapping.loss["wasserstein"]),
            alpha_fine * np.array(fine_mapping.loss["gromov_wasserstein"]),
            rho_fine * np.array(fine_mapping.loss["marginal_constraint_dim1"]),
            rho_fine * np.array(fine_mapping.loss["marginal_constraint_dim2"]),
            eps_fine * np.array(fine_mapping.loss["regularization"]),
        ],
        labels=[
            "wasserstein",
            "gromov_wasserstein",
            "marginal_constraint_dim1",
            "marginal_constraint_dim2",
            "regularization",
        ],
        alpha=0.8,
    )
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_003.png
   :alt: Fine-grained mapping training loss
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 198-203

In this example, the computed sparse transport plan is not very sparse:
it stores about 60% of what the equivalent dense transport plan
would store.
When aligning distributions with a high number of points,
we usually want to keep this number much smaller.

.. GENERATED FROM PYTHON SOURCE LINES 203-209

.. code-block:: default


    sparsity_ratio = (
        100 * fine_mapping.pi.values().shape[0] / fine_mapping.pi.shape.numel()
    )
    print(f"Ratio of non-null coefficients: {sparsity_ratio:.2f}%")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Ratio of non-null coefficients: 86.10%




.. GENERATED FROM PYTHON SOURCE LINES 210-213

We can also have a look at the sparsity mask of the
fine-grained transport plan. In this particular example,
we don't expect it to show a particularly meaningful structure.

.. GENERATED FROM PYTHON SOURCE LINES 213-229

.. code-block:: default

    indices = fine_mapping.pi.indices()
    fine_mapping_as_scipy_coo = coo_matrix(
        (
            fine_mapping.pi.values(),
            (indices[0], indices[1]),
        ),
        shape=fine_mapping.pi.size(),
    )

    fig, ax = plt.subplots(figsize=(5, 5))
    ax.set_title("Sparsity mask of fine-grained mapping")
    ax.set_ylabel("Source vertices")
    ax.set_xlabel("Target vertices")
    plt.spy(fine_mapping_as_scipy_coo, precision="present", markersize=0.3)
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_004.png
   :alt: Sparsity mask of fine-grained mapping
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 230-232

We can observe the computed mappings between source
and target points in the feature space.

.. GENERATED FROM PYTHON SOURCE LINES 232-265

.. code-block:: default

    pi = fine_mapping.pi.to_dense()
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot()
    ax.set_aspect("equal", "datalim")
    ax.set_title("Mapping\ndisplayed in feature space")

    # Draw lines between matched points
    indices = torch.cartesian_prod(
        torch.arange(n_points_source), torch.arange(n_points_target)
    )
    segments = torch.stack(
        [
            source_features_train[:, indices[:, 0]],
            target_features_train[:, indices[:, 1]],
        ]
    ).permute(2, 0, 1)
    pi_normalized = pi / pi.sum(dim=1).reshape(-1, 1)
    line_segments = LineCollection(
        segments,
        alpha=pi_normalized.flatten().nan_to_num(),
        colors="black",
        lw=1,
        zorder=1,
    )
    ax.add_collection(line_segments)

    # Draw distributions
    ax.scatter(source_features_train[0], source_features_train[1], label="Source")
    ax.scatter(target_features_train[0], target_features_train[1], label="Target")

    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_005.png
   :alt: Mapping displayed in feature space
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_005.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 266-268

Finally, the fitted fine-grained model can transport unseen data
between source and target

.. GENERATED FROM PYTHON SOURCE LINES 268-273

.. code-block:: default

    source_features_test = torch.rand(n_features_test, n_points_source)
    target_features_test = torch.rand(n_features_test, n_points_target)
    transformed_data = fine_mapping.transform(source_features_test)
    transformed_data.shape





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    torch.Size([2, 300])



.. GENERATED FROM PYTHON SOURCE LINES 274-275

.. code-block:: default

    assert transformed_data.shape == target_features_test.shape








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  0.874 seconds)

**Estimated memory usage:**  155 MB


.. _sphx_glr_download_auto_examples_00_basics_plot_2_2_coarse_to_fine.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_2_2_coarse_to_fine.py <plot_2_2_coarse_to_fine.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_2_2_coarse_to_fine.ipynb <plot_2_2_coarse_to_fine.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
