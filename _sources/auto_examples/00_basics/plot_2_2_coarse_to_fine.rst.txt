
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/00_basics/plot_2_2_coarse_to_fine.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_00_basics_plot_2_2_coarse_to_fine.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_00_basics_plot_2_2_coarse_to_fine.py:


Transport distributions using sparse solvers
============================================

In this example, we sample 2 toy distributions and compute
a sparse fugw alignment between them.
Sparse alignments are typically used when both aligned distributions
have more than 10k points.

.. GENERATED FROM PYTHON SOURCE LINES 11-22

.. code-block:: default


    import matplotlib.pyplot as plt
    import numpy as np
    import torch

    from fugw.mappings import FUGW, FUGWSparse
    from fugw.scripts import coarse_to_fine
    from fugw.utils import init_mock_distribution
    from matplotlib.collections import LineCollection
    from scipy.sparse import coo_matrix








.. GENERATED FROM PYTHON SOURCE LINES 24-34

.. code-block:: default

    np.random.seed(4)
    torch.manual_seed(0)

    n_points_source = 300
    n_samples_source = 100
    n_points_target = 300
    n_samples_target = 100
    n_features_train = 2
    n_features_test = 2








.. GENERATED FROM PYTHON SOURCE LINES 35-36

Let us generate random training data for the source and target distributions

.. GENERATED FROM PYTHON SOURCE LINES 36-43

.. code-block:: default

    _, source_features_train, _, source_embeddings = init_mock_distribution(
        n_features_train, n_points_source
    )
    _, target_features_train, _, target_embeddings = init_mock_distribution(
        n_features_train, n_points_target
    )








.. GENERATED FROM PYTHON SOURCE LINES 44-45

We can visualize the generated features:

.. GENERATED FROM PYTHON SOURCE LINES 45-54

.. code-block:: default

    fig = plt.figure(figsize=(4, 4))
    ax = fig.add_subplot()
    ax.set_title("Source and target features")
    ax.set_aspect("equal", "datalim")
    ax.scatter(source_features_train[0], source_features_train[1], label="Source")
    ax.scatter(target_features_train[0], target_features_train[1], label="Target")
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_001.png
   :alt: Source and target features
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 55-57

Do not forget to normalize features and embeddings
before fitting the models.

.. GENERATED FROM PYTHON SOURCE LINES 57-72

.. code-block:: default


    source_features_train_normalized = source_features_train / torch.linalg.norm(
        source_features_train, dim=1
    ).reshape(-1, 1)
    target_features_train_normalized = target_features_train / torch.linalg.norm(
        target_features_train, dim=1
    ).reshape(-1, 1)

    source_embeddings_normalized, source_d_max = coarse_to_fine.random_normalizing(
        source_embeddings
    )
    target_embeddings_normalized, target_d_max = coarse_to_fine.random_normalizing(
        target_embeddings
    )








.. GENERATED FROM PYTHON SOURCE LINES 73-75

Let us define the coarse and fine-grained optimization problems to solve.
We also specify which solver to use at each of the 2 steps:

.. GENERATED FROM PYTHON SOURCE LINES 75-87

.. code-block:: default

    coarse_mapping = FUGW(alpha=0.5, eps=1e-4)
    coarse_mapping_solver = "mm"
    coarse_mapping_solver_params = {
        "tol_uot": 1e-10,
    }

    fine_mapping = FUGWSparse(alpha=0.5, eps=1e-4)
    fine_mapping_solver = "mm"
    fine_mapping_solver_params = {
        "tol_uot": 1e-10,
    }








.. GENERATED FROM PYTHON SOURCE LINES 90-97

Now, let us fit both the coarse and fine-grained mappings.
The coarse mapping is fitted on a limited number
of points from the source and target distributions.
You should carefully set the source and target ``selection_radius``
as they will greatly affect the sparsity of the computed mappings.
They should usally be set using domain knowledge related to the distributions
you are trying to align.

.. GENERATED FROM PYTHON SOURCE LINES 97-122

.. code-block:: default

    _, _ = coarse_to_fine.fit(
        # Source and target's features and embeddings
        source_features=source_features_train_normalized,
        target_features=target_features_train_normalized,
        source_geometry_embeddings=source_embeddings_normalized,
        target_geometry_embeddings=target_embeddings_normalized,
        # Parametrize step 1 (coarse alignment between source and target)
        source_sample_size=n_samples_source,
        target_sample_size=n_samples_target,
        coarse_mapping=coarse_mapping,
        coarse_mapping_solver=coarse_mapping_solver,
        coarse_mapping_solver_params=coarse_mapping_solver_params,
        # Parametrize step 2 (selection of pairs of indices present in
        # fine-grained's sparsity mask)
        coarse_pairs_selection_method="topk",
        source_selection_radius=1 / source_d_max,
        target_selection_radius=1 / target_d_max,
        # Parametrize step 3 (fine-grained alignment)
        fine_mapping=fine_mapping,
        fine_mapping_solver=fine_mapping_solver,
        fine_mapping_solver_params=fine_mapping_solver_params,
        # Misc
        verbose=True,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none



    [16:38:22] BCD step 1/10   FUGW loss:      0.028055913746356964     dense.py:360
               (base)     0.02814635820686817 (entropic)                            


               BCD step 2/10   FUGW loss:      0.025683855637907982     dense.py:360
               (base)     0.025863073766231537 (entropic)                           


    [16:38:23] BCD step 3/10   FUGW loss:      0.016268832609057426     dense.py:360
               (base)     0.01665913127362728 (entropic)                            


               BCD step 4/10   FUGW loss:      0.011751125566661358     dense.py:360
               (base)     0.012296381406486034 (entropic)                           


               BCD step 5/10   FUGW loss:      0.010866605676710606     dense.py:360
               (base)     0.011479916982352734 (entropic)                           


    [16:38:24] BCD step 6/10   FUGW loss:      0.010522968135774136     dense.py:360
               (base)     0.011175187304615974 (entropic)                           


               BCD step 7/10   FUGW loss:      0.010338868945837021     dense.py:360
               (base)     0.011017151176929474 (entropic)                           


    [16:38:25] BCD step 8/10   FUGW loss:      0.010221882723271847     dense.py:360
               (base)     0.010919460095465183 (entropic)                           


    [16:38:26] BCD step 9/10   FUGW loss:      0.0101405568420887       dense.py:360
               (base)       0.010853287763893604 (entropic)                         


    [16:38:27] BCD step 10/10  FUGW loss:      0.0100807324051857       dense.py:360
               (base)       0.01080571860074997 (entropic)                          
      100% Sparsity mask ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200/200 0:00:01 < 0:00:00
    /github/workspace/src/fugw/utils.py:51: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)
      return x.to(device, dtype).to_sparse_csr()


    [16:38:39] BCD step 1/10   FUGW loss:      0.021763041615486145    sparse.py:478
               (base)     0.02189093828201294 (entropic)                            


    [16:38:42] BCD step 2/10   FUGW loss:      0.017754876986145973    sparse.py:478
               (base)     0.01801164820790291 (entropic)                            


    [16:38:45] BCD step 3/10   FUGW loss:      0.011553710326552391    sparse.py:478
               (base)     0.012020763009786606 (entropic)                           


    [16:38:47] BCD step 4/10   FUGW loss:      0.009638299234211445    sparse.py:478
               (base)     0.010233832523226738 (entropic)                           


    [16:38:50] BCD step 5/10   FUGW loss:      0.008976257406175137    sparse.py:478
               (base)     0.009645415470004082 (entropic)                           


    [16:38:52] BCD step 6/10   FUGW loss:      0.008657296188175678    sparse.py:478
               (base)     0.009374301880598068 (entropic)                           


    [16:38:55] BCD step 7/10   FUGW loss:      0.008474555797874928    sparse.py:478
               (base)     0.009225510992109776 (entropic)                           


    [16:38:59] BCD step 8/10   FUGW loss:      0.008358475752174854    sparse.py:478
               (base)     0.009134968742728233 (entropic)                           


    [16:39:04] BCD step 9/10   FUGW loss:      0.008279440924525261    sparse.py:478
               (base)     0.009075913578271866 (entropic)                           


    [16:39:09] BCD step 10/10  FUGW loss:      0.008222405798733234    sparse.py:478
               (base)     0.009034985676407814 (entropic)                           




.. GENERATED FROM PYTHON SOURCE LINES 123-125

Both the coarse and fine-grained transport plans can be accessed
after the models have been fitted

.. GENERATED FROM PYTHON SOURCE LINES 125-131

.. code-block:: default

    print(f"Coarse transport plan's total mass: {coarse_mapping.pi.sum():.5f}")
    print(
        "Fine-grained transport plan's total mass:"
        f" {torch.sparse.sum(fine_mapping.pi):.5f}"
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Coarse transport plan's total mass: 0.99800
    Fine-grained transport plan's total mass: 0.99842




.. GENERATED FROM PYTHON SOURCE LINES 132-134

Here is the evolution of the FUGW loss during training
of the coarse mapping, with and without the entropic term:

.. GENERATED FROM PYTHON SOURCE LINES 134-148

.. code-block:: default


    fig, ax = plt.subplots(figsize=(4, 4))
    ax.set_title("Coarse mapping training loss")
    ax.set_ylabel("Loss")
    ax.set_xlabel("BCD step")
    ax.plot(coarse_mapping.loss_steps, coarse_mapping.loss, label="FUGW loss")
    ax.plot(
        coarse_mapping.loss_steps,
        coarse_mapping.loss_entropic,
        label="FUGW entropic loss",
    )
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_002.png
   :alt: Coarse mapping training loss
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 149-150

And here is that of the fine-grained mapping:

.. GENERATED FROM PYTHON SOURCE LINES 150-164

.. code-block:: default


    fig, ax = plt.subplots(figsize=(4, 4))
    ax.set_title("Fine-grained mapping training loss")
    ax.set_ylabel("Loss")
    ax.set_xlabel("BCD step")
    ax.plot(fine_mapping.loss_steps, fine_mapping.loss, label="FUGW loss")
    ax.plot(
        fine_mapping.loss_steps,
        fine_mapping.loss_entropic,
        label="FUGW entropic loss",
    )
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_003.png
   :alt: Fine-grained mapping training loss
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 165-170

In this example, the computed sparse transport plan is not very sparse:
it stores about 60% of what the equivalent dense transport plan
would store.
When aligning distributions with a high number of points,
we usually want to keep this number much smaller.

.. GENERATED FROM PYTHON SOURCE LINES 170-176

.. code-block:: default


    sparsity_ratio = (
        100 * fine_mapping.pi.values().shape[0] / fine_mapping.pi.shape.numel()
    )
    print(f"Ratio of non-null coefficients: {sparsity_ratio:.2f}%")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Ratio of non-null coefficients: 63.17%




.. GENERATED FROM PYTHON SOURCE LINES 177-180

We can also have a look at the sparsity mask of the
fine-grained transport plan. In this particular example,
we don't expect it to show a particularly meaningful structure.

.. GENERATED FROM PYTHON SOURCE LINES 180-196

.. code-block:: default

    indices = fine_mapping.pi.indices()
    fine_mapping_as_scipy_coo = coo_matrix(
        (
            fine_mapping.pi.values(),
            (indices[0], indices[1]),
        ),
        shape=fine_mapping.pi.size(),
    )

    fig, ax = plt.subplots(figsize=(5, 5))
    ax.set_title("Sparsity mask of fine-grained mapping")
    ax.set_ylabel("Source vertices")
    ax.set_xlabel("Target vertices")
    plt.spy(fine_mapping_as_scipy_coo, precision="present", markersize=0.3)
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_004.png
   :alt: Sparsity mask of fine-grained mapping
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 197-199

We can observe the computed mappings between source
and target points in the feature space.

.. GENERATED FROM PYTHON SOURCE LINES 199-228

.. code-block:: default

    pi = fine_mapping.pi.to_dense()
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot()
    ax.set_aspect("equal", "datalim")
    ax.set_title("Mapping\ndisplayed in feature space")

    # Draw lines between matched points
    indices = torch.cartesian_prod(
        torch.arange(n_points_source), torch.arange(n_points_target)
    )
    segments = torch.stack(
        [
            source_features_train[:, indices[:, 0]],
            target_features_train[:, indices[:, 1]],
        ]
    ).permute(2, 0, 1)
    pi_normalized = pi / pi.sum(dim=1).reshape(-1, 1)
    line_segments = LineCollection(
        segments, alpha=pi_normalized.flatten(), colors="black", lw=1, zorder=1
    )
    ax.add_collection(line_segments)

    # Draw distributions
    ax.scatter(source_features_train[0], source_features_train[1], label="Source")
    ax.scatter(target_features_train[0], target_features_train[1], label="Target")

    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_005.png
   :alt: Mapping displayed in feature space
   :srcset: /auto_examples/00_basics/images/sphx_glr_plot_2_2_coarse_to_fine_005.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 229-231

Finally, the fitted fine-grained model can transport unseen data
between source and target

.. GENERATED FROM PYTHON SOURCE LINES 231-236

.. code-block:: default

    source_features_test = torch.rand(n_features_test, n_points_source)
    target_features_test = torch.rand(n_features_test, n_points_target)
    transformed_data = fine_mapping.transform(source_features_test)
    transformed_data.shape





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    torch.Size([2, 300])



.. GENERATED FROM PYTHON SOURCE LINES 237-238

.. code-block:: default

    assert transformed_data.shape == target_features_test.shape








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  55.815 seconds)

**Estimated memory usage:**  1544 MB


.. _sphx_glr_download_auto_examples_00_basics_plot_2_2_coarse_to_fine.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_2_2_coarse_to_fine.py <plot_2_2_coarse_to_fine.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_2_2_coarse_to_fine.ipynb <plot_2_2_coarse_to_fine.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
