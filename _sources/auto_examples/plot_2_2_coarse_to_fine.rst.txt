
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_2_2_coarse_to_fine.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_2_2_coarse_to_fine.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_2_2_coarse_to_fine.py:


Transport distributions containing more than 10k points
=======================================================

.. GENERATED FROM PYTHON SOURCE LINES 7-78




.. rst-class:: sphx-glr-script-out

 .. code-block:: none



    [17:47:54] BCD step 1/10   FUGW loss:      0.033702339977025986     dense.py:342
               (base)     0.033903855830430984 (entropic)                           


               BCD step 2/10   FUGW loss:      0.03309490531682968      dense.py:342
               (base)      0.033605094999074936 (entropic)                          


               BCD step 3/10   FUGW loss:      0.03274110332131386      dense.py:342
               (base)      0.03349883109331131 (entropic)                           


               BCD step 4/10   FUGW loss:      0.03253242000937462      dense.py:342
               (base)      0.03346032649278641 (entropic)                           


               BCD step 5/10   FUGW loss:      0.03240799531340599      dense.py:342
               (base)      0.03344637155532837 (entropic)                           


               BCD step 6/10   FUGW loss:      0.0323326401412487       dense.py:342
               (base)       0.03344091773033142 (entropic)                          


               BCD step 7/10   FUGW loss:      0.032287150621414185     dense.py:342
               (base)     0.033439118415117264 (entropic)                           


               BCD step 8/10   FUGW loss:      0.03225910663604736      dense.py:342
               (base)      0.03343821316957474 (entropic)                           
      100% Sparsity mask ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300/300 0:00:02 < 0:00:00
    /github/workspace/src/fugw/transformers/utils.py:149: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)
      return x.to(device, dtype).to_sparse_csr()


    [17:48:10] BCD step 1/10   FUGW loss:      0.09190735965967178     sparse.py:460
               (base)      0.10248613357543945 (entropic)                           


    [17:48:13] BCD step 2/10   FUGW loss:      0.07255856692790985     sparse.py:460
               (base)      0.0914413332939148 (entropic)                            


    [17:48:15] BCD step 3/10   FUGW loss:      0.049713876098394394    sparse.py:460
               (base)     0.08154833316802979 (entropic)                            


    [17:48:18] BCD step 4/10   FUGW loss:      0.045637428760528564    sparse.py:460
               (base)     0.08077586442232132 (entropic)                            


    [17:48:20] BCD step 5/10   FUGW loss:      0.04527181759476662     sparse.py:460
               (base)      0.08072327077388763 (entropic)                           


    [17:48:23] BCD step 6/10   FUGW loss:      0.04517510160803795     sparse.py:460
               (base)      0.08067489415407181 (entropic)                           


    [17:48:25] BCD step 7/10   FUGW loss:      0.045062415301799774    sparse.py:460
               (base)     0.0806085392832756 (entropic)                             


    [17:48:28] BCD step 8/10   FUGW loss:      0.04487589746713638     sparse.py:460
               (base)      0.08050280809402466 (entropic)                           


    [17:48:30] BCD step 9/10   FUGW loss:      0.0445578470826149      sparse.py:460
               (base)       0.08032988011837006 (entropic)                          


    [17:48:33] BCD step 10/10  FUGW loss:      0.04408379644155502     sparse.py:460
               (base)      0.08007900416851044 (entropic)                           
    Coarse transport plan's total mass: 0.9926271438598633
    Fine-scale transport plan's total mass: 0.9793401956558228






|

.. code-block:: default

    import torch

    from fugw.scripts import coarse_to_fine
    from fugw.transformers import FUGW, FUGWSparse
    from fugw.transformers.utils import init_mock_distribution

    torch.manual_seed(0)

    n_voxels_source = 300
    n_samples_source = 150
    n_voxels_target = 300
    n_samples_target = 150
    n_features_train = 10
    n_features_test = 5

    # Generate random training data for source and target distributions
    _, source_features, _, source_embeddings = init_mock_distribution(
        n_features_train, n_voxels_source
    )
    _, target_features, _, target_embeddings = init_mock_distribution(
        n_features_train, n_voxels_target
    )

    # Define the optimization problem to solve
    coarse_model = FUGW(alpha=0.5)
    fine_model = FUGWSparse(alpha=0.5)

    # Specify which solvers to use at each step
    coarse_model_fit_params = {
        "uot_solver": "mm",
        "tol_uot": 1e-10,
        "nits_uot": 100,
    }

    fine_model_fit_params = {
        "uot_solver": "mm",
        "tol_uot": 1e-10,
    }

    # Fit transport plans
    coarse_to_fine.fit(
        coarse_model=coarse_model,
        coarse_model_fit_params=coarse_model_fit_params,
        coarse_pairs_selection_method="topk",
        source_selection_radius=1,
        target_selection_radius=1,
        fine_model=fine_model,
        fine_model_fit_params=fine_model_fit_params,
        source_sample_size=n_samples_source,
        target_sample_size=n_samples_target,
        source_features=source_features,
        target_features=target_features,
        source_geometry_embeddings=source_embeddings,
        target_geometry_embeddings=target_embeddings,
        verbose=True,
    )

    # Both the coarse and fine-scale transport plans can be accessed
    # after the models have been fitted
    print(f"Coarse transport plan's total mass: {coarse_model.pi.sum()}")
    print(
        "Fine-scale transport plan's total mass:"
        f" {torch.sparse.sum(fine_model.pi)}"
    )

    # Finally, the fitted fine model can transport unseen data
    # between source and target
    source_features_test = torch.rand(n_features_test, n_voxels_source)
    target_features_test = torch.rand(n_features_test, n_voxels_target)
    transformed_data = fine_model.transform(source_features_test)
    assert transformed_data.shape == target_features_test.shape


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  39.486 seconds)


.. _sphx_glr_download_auto_examples_plot_2_2_coarse_to_fine.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_2_2_coarse_to_fine.py <plot_2_2_coarse_to_fine.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_2_2_coarse_to_fine.ipynb <plot_2_2_coarse_to_fine.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
