
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_2_2_coarse_to_fine.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_2_2_coarse_to_fine.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_2_2_coarse_to_fine.py:


Transport distributions containing more than 10k points
=======================================================

.. GENERATED FROM PYTHON SOURCE LINES 7-78




.. rst-class:: sphx-glr-script-out

 .. code-block:: none



    [17:56:56] BCD step 1/10   FUGW loss:      0.03370232507586479      dense.py:342
               (base)      0.03390384092926979 (entropic)                           


    [17:56:57] BCD step 2/10   FUGW loss:      0.03309480473399162      dense.py:342
               (base)      0.03360499441623688 (entropic)                           


               BCD step 3/10   FUGW loss:      0.03274102881550789      dense.py:342
               (base)      0.03349875658750534 (entropic)                           


               BCD step 4/10   FUGW loss:      0.032532356679439545     dense.py:342
               (base)     0.033460263162851334 (entropic)                           


               BCD step 5/10   FUGW loss:      0.032407741993665695     dense.py:342
               (base)     0.03344612196087837 (entropic)                            


               BCD step 6/10   FUGW loss:      0.032332565635442734     dense.py:342
               (base)     0.03344084694981575 (entropic)                            


               BCD step 7/10   FUGW loss:      0.03228721022605896      dense.py:342
               (base)      0.03343917801976204 (entropic)                           


               BCD step 8/10   FUGW loss:      0.032258931547403336     dense.py:342
               (base)     0.03343803808093071 (entropic)                            


               BCD step 9/10   FUGW loss:      0.03224209323525429      dense.py:342
               (base)      0.03343801572918892 (entropic)                           
      100% Sparsity mask ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300/300 0:00:02 < 0:00:00
    /github/workspace/src/fugw/mappings/utils.py:149: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)
      return x.to(device, dtype).to_sparse_csr()


    [17:57:17] BCD step 1/10   FUGW loss:      0.09200602024793625     sparse.py:460
               (base)      0.10248927772045135 (entropic)                           


    [17:57:20] BCD step 2/10   FUGW loss:      0.07457966357469559     sparse.py:460
               (base)      0.0923711508512497 (entropic)                            


    [17:57:23] BCD step 3/10   FUGW loss:      0.048064764589071274    sparse.py:460
               (base)     0.08005882799625397 (entropic)                            


    [17:57:27] BCD step 4/10   FUGW loss:      0.041944701224565506    sparse.py:460
               (base)     0.0785556510090828 (entropic)                             


    [17:57:30] BCD step 5/10   FUGW loss:      0.0409933440387249      sparse.py:460
               (base)       0.07823925465345383 (entropic)                          


    [17:57:33] BCD step 6/10   FUGW loss:      0.04059062525629997     sparse.py:460
               (base)      0.07805091142654419 (entropic)                           


    [17:57:36] BCD step 7/10   FUGW loss:      0.040390871465206146    sparse.py:460
               (base)     0.07795359194278717 (entropic)                            


    [17:57:40] BCD step 8/10   FUGW loss:      0.040293991565704346    sparse.py:460
               (base)     0.07790567725896835 (entropic)                            


    [17:57:43] BCD step 9/10   FUGW loss:      0.040249053388834       sparse.py:460
               (base)        0.07788366079330444 (entropic)                         


    [17:57:46] BCD step 10/10  FUGW loss:      0.040228258818387985    sparse.py:460
               (base)     0.07787306606769562 (entropic)                            
    Coarse transport plan's total mass: 0.9926269054412842
    Fine-scale transport plan's total mass: 0.9798995852470398






|

.. code-block:: default

    import torch

    from fugw.scripts import coarse_to_fine
    from fugw.mappings import FUGW, FUGWSparse
    from fugw.mappings.utils import init_mock_distribution

    torch.manual_seed(0)

    n_voxels_source = 300
    n_samples_source = 150
    n_voxels_target = 300
    n_samples_target = 150
    n_features_train = 10
    n_features_test = 5

    # Generate random training data for source and target distributions
    _, source_features, _, source_embeddings = init_mock_distribution(
        n_features_train, n_voxels_source
    )
    _, target_features, _, target_embeddings = init_mock_distribution(
        n_features_train, n_voxels_target
    )

    # Define the optimization problem to solve
    coarse_model = FUGW(alpha=0.5)
    fine_model = FUGWSparse(alpha=0.5)

    # Specify which solvers to use at each step
    coarse_model_fit_params = {
        "uot_solver": "mm",
        "tol_uot": 1e-10,
        "nits_uot": 100,
    }

    fine_model_fit_params = {
        "uot_solver": "mm",
        "tol_uot": 1e-10,
    }

    # Fit transport plans
    coarse_to_fine.fit(
        coarse_model=coarse_model,
        coarse_model_fit_params=coarse_model_fit_params,
        coarse_pairs_selection_method="topk",
        source_selection_radius=1,
        target_selection_radius=1,
        fine_model=fine_model,
        fine_model_fit_params=fine_model_fit_params,
        source_sample_size=n_samples_source,
        target_sample_size=n_samples_target,
        source_features=source_features,
        target_features=target_features,
        source_geometry_embeddings=source_embeddings,
        target_geometry_embeddings=target_embeddings,
        verbose=True,
    )

    # Both the coarse and fine-scale transport plans can be accessed
    # after the models have been fitted
    print(f"Coarse transport plan's total mass: {coarse_model.pi.sum()}")
    print(
        "Fine-scale transport plan's total mass:"
        f" {torch.sparse.sum(fine_model.pi)}"
    )

    # Finally, the fitted fine model can transport unseen data
    # between source and target
    source_features_test = torch.rand(n_features_test, n_voxels_source)
    target_features_test = torch.rand(n_features_test, n_voxels_target)
    transformed_data = fine_model.transform(source_features_test)
    assert transformed_data.shape == target_features_test.shape


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  49.985 seconds)


.. _sphx_glr_download_auto_examples_plot_2_2_coarse_to_fine.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_2_2_coarse_to_fine.py <plot_2_2_coarse_to_fine.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_2_2_coarse_to_fine.ipynb <plot_2_2_coarse_to_fine.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
