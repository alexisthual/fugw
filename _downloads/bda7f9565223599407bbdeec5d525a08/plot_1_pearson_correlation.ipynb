{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Monitor the Pearson correlation during training with callbacks\n\nIn this example, we use a callback function to monitor the Pearson correlation\nbetween transformed and target features at each iteration of\nthe block-coordinate descent (BCD) algorithm.\nThis can be useful to detect numerical errors, or to check that the\nmapping is not over-fitting training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from functools import partial\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport time\nfrom nilearn import datasets, image\nfrom rich.console import Console\nfrom scipy.spatial import distance_matrix\nfrom scipy.linalg import norm\n\nfrom fugw.mappings import FUGW\nfrom fugw.utils import _make_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first fetch 6 contrasts for each subject from the localizer dataset.\nWe use 3 contrasts for training and 3 contrasts for validation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_subjects = 2\n\ncontrasts = [\n    \"sentence reading\",\n    \"calculation vs sentences\",\n    \"left vs right button press\",\n    \"sentence reading vs checkerboard\",\n    \"sentence listening\",\n    \"left button press\",\n]\nn_training_contrasts = 3\n\nbrain_data = datasets.fetch_localizer_contrasts(\n    contrasts,\n    n_subjects=n_subjects,\n    get_anats=True,\n    get_masks=True,\n)\n\nsource_imgs_paths = brain_data[\"cmaps\"][0 : len(contrasts)]\ntarget_imgs_paths = brain_data[\"cmaps\"][len(contrasts) : 2 * len(contrasts)]\nsource_mask = brain_data[\"masks\"][0]\n\nsource_im = image.load_img(source_imgs_paths)\ntarget_im = image.load_img(target_imgs_paths)\nmask = image.load_img(source_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then downsample the images by 5 to reduce the computational cost.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SCALE_FACTOR = 5\n\nresized_source_affine = source_im.affine.copy() * SCALE_FACTOR\nresized_target_affine = target_im.affine.copy() * SCALE_FACTOR\n\nsource_im_resized = image.resample_img(source_im, resized_source_affine)\ntarget_im_resized = image.resample_img(target_im, resized_target_affine)\nmask_resized = image.resample_img(mask, resized_source_affine)\n\nsource_maps = np.nan_to_num(source_im_resized.get_fdata())\ntarget_maps = np.nan_to_num(target_im_resized.get_fdata())\nsegmentation = mask_resized.get_fdata()\n\ncoordinates = np.argwhere(segmentation > 0)\n\nsource_features = source_maps[\n    coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]\n].T\ntarget_features = target_maps[\n    coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]\n].T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then compute the distance matrix between voxel coordinates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_geometry = distance_matrix(coordinates, coordinates)\ntarget_geometry = source_geometry.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to avoid numerical errors when fitting the mapping, we normalize\nall feature and geometry arrays.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_features_normalized = source_features / np.linalg.norm(\n    source_features, axis=1\n).reshape(-1, 1)\ntarget_features_normalized = target_features / np.linalg.norm(\n    target_features, axis=1\n).reshape(-1, 1)\nsource_geometry_normalized = source_geometry / np.max(source_geometry)\ntarget_geometry_normalized = target_geometry / np.max(target_geometry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first define a function to compute the Pearson correlation\nbetween two tensors. Such function is not available in PyTorch,\nbut it is easy to implement.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def pearson_corr(a, b, plan):\n    \"\"\"\n    Compute the Pearson correlation between transformed\n    source features and target features.\n    \"\"\"\n    if torch.is_tensor(a):\n        x = a.detach().cpu().numpy()\n    elif isinstance(a, np.ndarray):\n        x = a\n    elif isinstance(a, list):\n        x = np.array(a)\n    else:\n        raise ValueError(\"a must be a list, np.ndarray or torch.Tensor\")\n\n    if torch.is_tensor(b):\n        y = b.detach().cpu().numpy()\n    elif isinstance(b, np.ndarray):\n        y = b\n    elif isinstance(b, list):\n        y = np.array(b)\n    else:\n        raise ValueError(\"b must be a list, np.ndarray or torch.Tensor\")\n\n    # Compute the transformed features\n    x_transformed = (\n        (plan.T @ x.T / plan.sum(dim=0).reshape(-1, 1)).T.detach().cpu()\n    )\n\n    return pearson_r(x_transformed, y)\n\n\ndef pearson_r(a, b):\n    \"\"\"Compute Pearson correlation between x and y.\n\n    Compute Pearson correlation between 2d arrays x and y\n    along the samples axis.\n    Adapted from scipy.stats.pearsonr.\n\n    Parameters\n    ----------\n    a: np.ndarray of size (n_samples, n_features)\n    b: np.ndarray of size (n_samples, n_features)\n\n    Returns\n    -------\n    r: np.ndarray of size (n_samples,)\n    \"\"\"\n    if torch.is_tensor(a):\n        x = a.detach().cpu().numpy()\n    elif isinstance(a, np.ndarray):\n        x = a\n    elif isinstance(a, list):\n        x = np.array(a)\n    else:\n        raise ValueError(\"a must be a list, np.ndarray or torch.Tensor\")\n\n    if torch.is_tensor(b):\n        y = b.detach().cpu().numpy()\n    elif isinstance(b, np.ndarray):\n        y = b\n    elif isinstance(b, list):\n        y = np.array(b)\n    else:\n        raise ValueError(\"b must be a list, np.ndarray or torch.Tensor\")\n\n    dtype = type(1.0 + x[0, 0] + y[0, 0])\n\n    xmean = x.mean(axis=1, dtype=dtype)\n    ymean = y.mean(axis=1, dtype=dtype)\n\n    # By using `astype(dtype)`, we ensure that the intermediate calculations\n    # use at least 64 bit floating point.\n    xm = x.astype(dtype) - xmean[:, np.newaxis]\n    ym = y.astype(dtype) - ymean[:, np.newaxis]\n\n    # Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),\n    # scipy.linalg.norm(xm) does not overflow if xm is, for example,\n    # [-5e210, 5e210, 3e200, -3e200]\n    normxm = norm(xm, axis=1)\n    normym = norm(ym, axis=1)\n\n    r = np.sum(\n        (xm / normxm[:, np.newaxis]) * (ym / normym[:, np.newaxis]), axis=1\n    )\n\n    return r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then define a callback function that computes the\nPearson correlation between transformed features and\ntarget features at each BCD iteration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize the transport plan with ones and normalize it\ninit_plan = torch.ones(\n    (\n        source_features_normalized.shape[1],\n        source_features_normalized.shape[1],\n    )\n)\n\ninit_plan_normalized = init_plan / init_plan.sum()\n\n# Initialize the list of Pearson correlations by fitting\n# source features with the initial plan\ncorr_bcd_steps = [\n    pearson_corr(\n        source_features_normalized[n_training_contrasts:],\n        target_features_normalized[n_training_contrasts:],\n        init_plan_normalized,\n    )\n]\n\n\ndef correlation_callback(\n    locals,\n    source_features=None,\n    target_features=None,\n    device=torch.device(\"cpu\"),\n):\n    console = Console()\n\n    # Get current transport plan and tensorize features\n    pi = locals[\"pi\"]\n    source_features_tensor = _make_tensor(source_features, device)\n    target_features_tensor = _make_tensor(target_features, device)\n\n    # Compute the Pearson correlation and append it to the list\n    corr = pearson_corr(source_features_tensor, target_features_tensor, pi)\n    corr_bcd_steps.append(corr)\n\n    console.log(\"Pearson correlation: \", corr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now fit the mapping using the sinkhorn solver and 5 BCD iterations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"\n\nstart_time = time.time()\nmapping = FUGW(alpha=0.5, rho=1, eps=1e-4)\n_ = mapping.fit(\n    source_features=source_features_normalized[:n_training_contrasts],\n    target_features=target_features_normalized[:n_training_contrasts],\n    source_geometry=source_geometry_normalized,\n    target_geometry=target_geometry_normalized,\n    source_features_val=source_features_normalized[n_training_contrasts:],\n    target_features_val=target_features_normalized[n_training_contrasts:],\n    init_plan=init_plan_normalized,\n    solver=\"sinkhorn\",\n    solver_params={\n        \"nits_bcd\": 5,\n    },\n    callback_bcd=partial(\n        correlation_callback,\n        source_features=source_features_normalized[n_training_contrasts:],\n        target_features=target_features_normalized[n_training_contrasts:],\n        device=device,\n    ),\n    verbose=True,\n    device=device,\n)\ntotal_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Pearson correlation relative to each validation contrast and training\nloss evolution are then plotted for each BCD iteration. Notice how the\naverage across-voxel correlation spikes right after the first BCD\niteration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corr_bcd_steps = np.array(corr_bcd_steps)\n\nmean_corr = np.mean(corr_bcd_steps, axis=1)\nstd_corr = np.std(corr_bcd_steps, axis=1)\n\nfig, ax1 = plt.subplots()\n\ncolor = \"tab:red\"\nax1.set_xlabel(\"BCD Step\")\nax1.set_ylabel(\"FUGW loss\", color=color)\nax1.plot(mapping.loss_steps, mapping.loss[\"total\"], color=color)\nax1.tick_params(axis=\"y\", labelcolor=color)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\ncolor = \"tab:blue\"\nax2.set_ylabel(\"Pearson correlation\", color=color)\nfor i in range(len(source_features_normalized[n_training_contrasts:])):\n    ax2.plot(\n        mapping.loss_steps[: len(corr_bcd_steps)],\n        corr_bcd_steps[:, i],\n        color=color,\n        alpha=0.5,\n        linestyle=\"dashed\",\n        label=\"Individual contrasts\" if i == 0 else None,\n    )\nax2.set_label(\"Pearson correlation\")\n\nax2.plot(\n    mapping.loss_steps[: len(corr_bcd_steps)],\n    mean_corr,\n    color=\"blue\",\n    label=\"Average across-voxels correlation\",\n)\nax2.fill_between(\n    mapping.loss_steps[: len(corr_bcd_steps)],\n    mean_corr - std_corr,\n    mean_corr + std_corr,\n    color=color,\n    alpha=0.2,\n    label=\"Standard deviation\",\n)\nax2.set_ylim(0, 1)\nax2.tick_params(axis=\"y\", labelcolor=color)\nplt.title(\n    f\"Sinkhorn mapping training loss\\n Total training time = {total_time:.2f}s\"\n)\nfig.tight_layout()\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}