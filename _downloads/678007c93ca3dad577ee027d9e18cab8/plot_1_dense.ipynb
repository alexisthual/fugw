{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Transport distributions using dense solvers\n\nIn this example, we sample 2 toy distributions and compute\na dense fugw alignment between them.\nDense alignments are typically used when both aligned distributions\nhave less than 10k points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport torch\n\nfrom fugw.mappings import FUGW\nfrom fugw.utils import init_mock_distribution\nfrom matplotlib.collections import LineCollection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n\nn_points_source = 50\nn_points_target = 40\nn_features_train = 2\nn_features_test = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us generate random training data for the source and target distributions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, source_features_train, source_geometry, source_embeddings = (\n    init_mock_distribution(n_features_train, n_points_source)\n)\n_, target_features_train, target_geometry, target_embeddings = (\n    init_mock_distribution(n_features_train, n_points_target)\n)\nsource_features_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize the generated features:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(4, 4))\nax = fig.add_subplot()\nax.set_title(\"Source and target features\")\nax.set_aspect(\"equal\", \"datalim\")\nax.scatter(source_features_train[0], source_features_train[1], label=\"Source\")\nax.scatter(target_features_train[0], target_features_train[1], label=\"Target\")\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And embeddings:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\nax.set_title(\"Source and target embeddings (ie geometries)\")\nax.scatter(\n    source_embeddings[:, 0],\n    source_embeddings[:, 1],\n    source_embeddings[:, 2],\n    s=15,\n    label=\"Source\",\n)\nax.scatter(\n    target_embeddings[:, 0],\n    target_embeddings[:, 1],\n    target_embeddings[:, 2],\n    s=15,\n    label=\"Target\",\n)\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Features and geometries should be normalized before calling the solver\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_features_train_normalized = source_features_train / torch.linalg.norm(\n    source_features_train, dim=1\n).reshape(-1, 1)\ntarget_features_train_normalized = target_features_train / torch.linalg.norm(\n    target_features_train, dim=1\n).reshape(-1, 1)\n\nsource_geometry_normalized = source_geometry / source_geometry.max()\ntarget_geometry_normalized = target_geometry / target_geometry.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us define the optimization problem to solve\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mapping = FUGW(alpha=0.5, eps=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we fit a transport plan between source and target distributions\nusing a sinkhorn solver\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = mapping.fit(\n    source_features_train_normalized,\n    target_features_train_normalized,\n    source_geometry=source_geometry_normalized,\n    target_geometry=target_geometry_normalized,\n    solver=\"sinkhorn\",\n    verbose=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The transport plan can be accessed after the model has been fitted\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pi = mapping.pi\nprint(f\"Transport plan's total mass: {pi.sum():.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the evolution of the FUGW loss during training,\nwith and without the entropic term:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(4, 4))\nax.set_title(\"Mapping training loss\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"BCD step\")\nax.plot(mapping.loss_steps, mapping.loss, label=\"FUGW loss\")\nax.plot(mapping.loss_steps, mapping.loss_entropic, label=\"FUGW entropic loss\")\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the computed mapping\nThe computed mapping is stored in ``mapping.pi`` as a ``torch.Tensor``.\nIn this example, the transport plan is small enough that we can display\nit altogether.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(4, 4))\nax.set_title(\"Transport plan\")\nax.set_xlabel(\"target vertices\")\nax.set_ylabel(\"source vertices\")\nim = plt.imshow(pi, cmap=\"viridis\")\nplt.colorbar(im, ax=ax, shrink=0.8)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous figure of the transport plan tells us it is very sparse\nand not very entropic.\nAnother informative way to look at the plan consists in checking\nwhich points of the source and target distributions\nwere matched together in the feature space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(4, 4))\nax = fig.add_subplot()\nax.set_aspect(\"equal\", \"datalim\")\nax.set_title(\"Mapping\\ndisplayed in feature space\")\n\n# Draw lines between matched points\nindices = torch.cartesian_prod(\n    torch.arange(n_points_source), torch.arange(n_points_target)\n)\nsegments = torch.stack(\n    [\n        source_features_train[:, indices[:, 0]],\n        target_features_train[:, indices[:, 1]],\n    ]\n).permute(2, 0, 1)\npi_normalized = pi / pi.sum(dim=1).reshape(-1, 1)\nline_segments = LineCollection(\n    segments, alpha=pi_normalized.flatten(), colors=\"black\", lw=1, zorder=1\n)\nax.add_collection(line_segments)\n\n# Draw distributions\nax.scatter(source_features_train[0], source_features_train[1], label=\"Source\")\nax.scatter(target_features_train[0], target_features_train[1], label=\"Target\")\n\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, the fitted model can transport unseen data\nbetween source and target\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_features_test = torch.rand(n_features_test, n_points_source)\ntarget_features_test = torch.rand(n_features_test, n_points_target)\ntransformed_data = mapping.transform(source_features_test)\ntransformed_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert transformed_data.shape == target_features_test.shape"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}