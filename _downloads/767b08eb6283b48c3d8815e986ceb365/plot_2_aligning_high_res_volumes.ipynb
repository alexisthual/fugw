{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Align low-resolution brain volumes of 2 individuals with fMRI data\n\nIn this example, we align 2 low-resolution brain volumes\nusing 4 fMRI feature maps (z-score contrast maps).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom nilearn import datasets, image\nfrom fugw.mappings import FUGW, FUGWSparse\nfrom fugw.scripts import coarse_to_fine, lmds\n\nplt.rcParams[\"figure.dpi\"] = 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first fetch 5 contrasts for each subject from the localizer dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_subjects = 2\n\ncontrasts = [\n    \"sentence reading vs checkerboard\",\n    \"sentence listening\",\n    \"calculation vs sentences\",\n    \"left vs right button press\",\n    \"checkerboard\",\n]\nn_training_contrasts = 4\n\nbrain_data = datasets.fetch_localizer_contrasts(\n    contrasts,\n    n_subjects=n_subjects,\n    get_anats=True,\n)\n\nsource_imgs_paths = brain_data[\"cmaps\"][0 : len(contrasts)]\ntarget_imgs_paths = brain_data[\"cmaps\"][len(contrasts) : 2 * len(contrasts)]\n\nsource_im = image.load_img(source_imgs_paths)\ntarget_im = image.load_img(target_imgs_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's use a geometry of 7633 voxels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SCALE_FACTOR = 2\n\nsource_maps = np.nan_to_num(\n    source_im.get_fdata()[::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR]\n)\ntarget_maps = np.nan_to_num(\n    target_im.get_fdata()[::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR]\n)\n\nsegmentation_fine = np.logical_not(np.isnan(source_im.get_fdata()[:, :, :, 0]))\nsegmentation_coarse = segmentation_fine[\n    ::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR\n]\ncoordinates = np.array(np.nonzero(segmentation_coarse)).T\n\nsource_features = source_maps[\n    coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]\n].T\ntarget_features = target_maps[\n    coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]\n].T\n\nfig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\nax.scatter(coordinates[:, 0], coordinates[:, 1], coordinates[:, 2], marker=\"o\")\nax.view_init(10, 135)\nax.set_axis_off()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then compute the distance matrix between voxel coordinates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_geometry_embeddings = lmds.compute_lmds_volume(\n    segmentation_coarse\n).nan_to_num()\ntarget_geometry_embeddings = source_geometry_embeddings.clone()\n\n# Show the embedding shape\nprint(source_geometry_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to avoid numerical errors when fitting the mapping, we normalize\nboth the features and the geometry.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_features_normalized = source_features / np.linalg.norm(\n    source_features, axis=1\n).reshape(-1, 1)\ntarget_features_normalized = target_features / np.linalg.norm(\n    target_features, axis=1\n).reshape(-1, 1)\n\nsource_embeddings_normalized, source_distance_max = (\n    coarse_to_fine.random_normalizing(source_geometry_embeddings)\n)\ntarget_embeddings_normalized, target_distance_max = (\n    coarse_to_fine.random_normalizing(target_geometry_embeddings)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now fit the mapping using the sinkhorn solver and 3 BCD iterations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alpha_coarse = 0.5\nrho_coarse = 1\neps_coarse = 1e-4\ncoarse_mapping = FUGW(alpha=alpha_coarse, rho=rho_coarse, eps=eps_coarse)\ncoarse_mapping_solver = \"mm\"\ncoarse_mapping_solver_params = {\n    \"nits_bcd\": 5,\n    \"tol_uot\": 1e-10,\n}\n\nalpha_fine = 0.5\nrho_fine = 1\neps_fine = 1e-4\nfine_mapping = FUGWSparse(alpha=alpha_fine, rho=rho_fine, eps=eps_fine)\nfine_mapping_solver = \"mm\"\nfine_mapping_solver_params = {\n    \"nits_bcd\": 3,\n    \"tol_uot\": 1e-10,\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's subsample the vertices.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_sample = coarse_to_fine.sample_volume_uniformly(\n    segmentation_coarse,\n    embeddings=source_geometry_embeddings,\n    n_samples=1000,\n)\ntarget_sample = coarse_to_fine.sample_volume_uniformly(\n    segmentation_coarse,\n    embeddings=target_geometry_embeddings,\n    n_samples=1000,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train both the coarse and the fine mapping.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coarse_to_fine.fit(\n    # Source and target's features and embeddings\n    source_features=source_features_normalized[:n_training_contrasts, :],\n    target_features=target_features_normalized[:n_training_contrasts, :],\n    source_geometry_embeddings=source_embeddings_normalized,\n    target_geometry_embeddings=target_embeddings_normalized,\n    # Parametrize step 1 (coarse alignment between source and target)\n    source_sample=source_sample,\n    target_sample=target_sample,\n    coarse_mapping=coarse_mapping,\n    coarse_mapping_solver=coarse_mapping_solver,\n    coarse_mapping_solver_params=coarse_mapping_solver_params,\n    # Parametrize step 2 (selection of pairs of indices present in\n    # fine-grained's sparsity mask)\n    coarse_pairs_selection_method=\"topk\",\n    source_selection_radius=3 / source_distance_max,\n    target_selection_radius=3 / target_distance_max,\n    # Parametrize step 3 (fine-grained alignment)\n    fine_mapping=fine_mapping,\n    fine_mapping_solver=fine_mapping_solver,\n    fine_mapping_solver_params=fine_mapping_solver_params,\n    # Misc\n    verbose=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the probability map of target voxels being matched with\nthe 300th source voxel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pi = fine_mapping.pi\nvertex_index = 300\none_hot = np.zeros(source_features.shape[1])\none_hot[vertex_index] = 1.0\nprobability_map = fine_mapping.inverse_transform(one_hot)\n\nfig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\nax.scatter(\n    coordinates[:, 0],\n    coordinates[:, 1],\n    coordinates[:, 2],\n    marker=\"o\",\n    c=probability_map,\n    cmap=\"twilight\",\n    alpha=0.75,\n)\nax.text(\n    coordinates[vertex_index, 0],\n    coordinates[vertex_index, 1],\n    coordinates[vertex_index, 2] - 2,\n    \"x Source point\",\n    color=\"red\",\n)\nax.view_init(10, 135, 2)\nax.set_title(\n    \"Probability map of target voxels\\n\"\n    f\"being matched with source point {vertex_index}\"\n)\nax.set_axis_off()\nfig.colorbar(plt.cm.ScalarMappable(cmap=\"twilight\"), ax=ax)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now align test contrasts using the fitted fine mapping.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrast_index = -1\npredicted_target_features = fine_mapping.transform(\n    source_features[contrast_index, :]\n)\npredicted_target_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare the Pearson correlation between source and target features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corr_pre_mapping = np.corrcoef(\n    source_features[contrast_index, :], target_features[contrast_index, :]\n)[0, 1]\ncorr_post_mapping = np.corrcoef(\n    predicted_target_features, target_features[contrast_index, :]\n)[0, 1]\nprint(f\"Pearson Correlation pre-mapping: {corr_pre_mapping:.2f}\")\nprint(f\"Pearson Correlation post-mapping: {corr_post_mapping:.2f}\")\nprint(\n    \"Relative improvement:\"\n    f\" {(corr_post_mapping - corr_pre_mapping) / corr_pre_mapping *100 :.2f} %\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the transporting feature maps of the test set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=plt.figaspect(0.3))\nfig.suptitle(\"Transporting feature maps of the test set\", size=16)\nax = fig.add_subplot(1, 2, 1, projection=\"3d\")\nax.scatter(\n    coordinates[:, 0],\n    coordinates[:, 1],\n    coordinates[:, 2],\n    marker=\"o\",\n    c=source_features_normalized[-1, :],\n    cmap=\"twilight\",\n)\nax.view_init(10, 135, 2)\nax.set_title(\"Source features\")\nax.set_axis_off()\n\nax = fig.add_subplot(1, 1, 1, projection=\"3d\")\nax.scatter(\n    coordinates[:, 0],\n    coordinates[:, 1],\n    coordinates[:, 2],\n    marker=\"o\",\n    c=predicted_target_features,\n    cmap=\"twilight\",\n)\nax.view_init(10, 135, 2)\nax.set_title(\"Predicted target features\")\nax.set_axis_off()\n\nax = fig.add_subplot(1, 2, 2, projection=\"3d\")\nax.scatter(\n    coordinates[:, 0],\n    coordinates[:, 1],\n    coordinates[:, 2],\n    marker=\"o\",\n    c=target_features_normalized[-1, :],\n    cmap=\"twilight\",\n)\nax.view_init(10, 135, 2)\nax.set_title(\"Actual target features\")\nax.set_axis_off()\nfig.colorbar(plt.cm.ScalarMappable(cmap=\"twilight\"), ax=ax)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}