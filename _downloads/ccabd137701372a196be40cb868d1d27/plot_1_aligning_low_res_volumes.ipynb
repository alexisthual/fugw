{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Align low-resolution brain volumes of 2 individuals with fMRI data\n\nIn this example, we align 2 low-resolution brain volumes\nusing 4 fMRI feature maps (z-score contrast maps).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom nilearn import datasets, image\nfrom scipy.spatial import distance_matrix\n\nfrom fugw.mappings import FUGW\n\nplt.rcParams[\"figure.dpi\"] = 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first fetch 5 contrasts for each subject from the localizer dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_subjects = 2\n\ncontrasts = [\n    \"sentence reading vs checkerboard\",\n    \"sentence listening\",\n    \"calculation vs sentences\",\n    \"left vs right button press\",\n    \"checkerboard\",\n]\nn_training_contrasts = 4\n\nbrain_data = datasets.fetch_localizer_contrasts(\n    contrasts,\n    n_subjects=n_subjects,\n    get_anats=True,\n)\n\nsource_imgs_paths = brain_data[\"cmaps\"][0 : len(contrasts)]\ntarget_imgs_paths = brain_data[\"cmaps\"][len(contrasts) : 2 * len(contrasts)]\n\nsource_im = image.load_img(source_imgs_paths)\ntarget_im = image.load_img(target_imgs_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then downsample the images by 3 to reduce the computational cost.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SCALE_FACTOR = 3\n\nsource_maps = np.nan_to_num(\n    source_im.get_fdata()[::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR]\n)\ntarget_maps = np.nan_to_num(\n    target_im.get_fdata()[::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR]\n)\n\nsegmentation_fine = np.logical_not(np.isnan(source_im.get_fdata()[:, :, :, 0]))\nsegmentation_coarse = segmentation_fine[\n    ::SCALE_FACTOR, ::SCALE_FACTOR, ::SCALE_FACTOR\n]\ncoordinates = np.array(np.nonzero(segmentation_coarse)).T\n\nsource_features = source_maps[\n    coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]\n].T\ntarget_features = target_maps[\n    coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]\n].T\n\nfig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\nax.scatter(coordinates[:, 0], coordinates[:, 1], coordinates[:, 2], marker=\"o\")\nax.view_init(10, 135)\nax.set_axis_off()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then compute the distance matrix between voxel coordinates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_geometry = distance_matrix(coordinates, coordinates)\ntarget_geometry = source_geometry.copy()\nplt.imshow(source_geometry)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\nax.scatter(\n    coordinates[1:, 0],\n    coordinates[1:, 1],\n    coordinates[1:, 2],\n    marker=\".\",\n    c=source_geometry[0, 1:],\n)\nax.scatter(\n    coordinates[0, 0],\n    coordinates[0, 1],\n    coordinates[0, 2],\n    marker=\"o\",\n    c=\"red\",\n)\nax.text(\n    coordinates[0, 0],\n    coordinates[0, 1],\n    coordinates[0, 2] - 2,\n    \"Source point\",\n    color=\"red\",\n)\nax.view_init(10, 135)\nax.set_axis_off()\nfig.colorbar(\n    plt.cm.ScalarMappable(cmap=\"viridis\"),\n    ax=ax,\n    label=\"Distance to source point\",\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to avoid numerical errors when fitting the mapping, we normalize\nboth the features and the geometry.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_features_normalized = source_features / np.linalg.norm(\n    source_features, axis=1\n).reshape(-1, 1)\ntarget_features_normalized = target_features / np.linalg.norm(\n    target_features, axis=1\n).reshape(-1, 1)\nsource_geometry_normalized = source_geometry / np.max(source_geometry)\ntarget_geometry_normalized = target_geometry / np.max(target_geometry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now fit the mapping using the sinkhorn solver and 3 BCD iterations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mapping = FUGW(alpha=0.5, rho=1, eps=1e-4)\n_ = mapping.fit(\n    source_features_normalized[:n_training_contrasts],\n    target_features_normalized[:n_training_contrasts],\n    source_geometry=source_geometry_normalized,\n    target_geometry=target_geometry_normalized,\n    solver=\"sinkhorn\",\n    solver_params={\n        \"nits_bcd\": 3,\n    },\n    verbose=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the probability map of target voxels being matched with\nthe 300th source voxel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pi = mapping.pi\nvertex_index = 300\nprobability_map = pi[vertex_index, :] / np.sqrt(\n    np.linalg.norm(pi[vertex_index, :])\n)\n\nfig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\nax.scatter(\n    coordinates[:, 0],\n    coordinates[:, 1],\n    coordinates[:, 2],\n    marker=\"o\",\n    c=probability_map,\n    cmap=\"twilight\",\n    alpha=0.75,\n)\nax.text(\n    coordinates[vertex_index, 0],\n    coordinates[vertex_index, 1],\n    coordinates[vertex_index, 2] - 2,\n    \"Source point\",\n    color=\"red\",\n)\nax.view_init(10, 135, 2)\nax.set_title(\n    \"Probability map of target voxels\\n\"\n    f\"being matched with source point {vertex_index}\"\n)\nax.set_axis_off()\nfig.colorbar(plt.cm.ScalarMappable(cmap=\"twilight\"), ax=ax)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now align test contrasts using the fitted mapping.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrast_index = -1\npredicted_target_features = mapping.transform(\n    source_features[contrast_index, :]\n)\npredicted_target_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare the Pearson correlation between source and target features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corr_pre_mapping = np.corrcoef(\n    source_features[contrast_index, :], target_features[contrast_index, :]\n)[0, 1]\ncorr_post_mapping = np.corrcoef(\n    predicted_target_features, target_features[contrast_index, :]\n)[0, 1]\nprint(f\"Pearson Correlation pre-mapping: {corr_pre_mapping:.2f}\")\nprint(f\"Pearson Correlation post-mapping: {corr_post_mapping:.2f}\")\nprint(\n    \"Relative improvement:\"\n    f\" {(corr_post_mapping - corr_pre_mapping) / corr_pre_mapping *100 :.2f} %\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the transporting feature maps of the test set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=plt.figaspect(0.3))\nfig.suptitle(\"Transporting feature maps of the test set\", size=16)\nax = fig.add_subplot(1, 2, 1, projection=\"3d\")\nax.scatter(\n    coordinates[:, 0],\n    coordinates[:, 1],\n    coordinates[:, 2],\n    marker=\"o\",\n    c=source_features_normalized[-1, :],\n    cmap=\"twilight\",\n)\nax.view_init(10, 135, 2)\nax.set_title(\"Source features\")\nax.set_axis_off()\n\nax = fig.add_subplot(1, 1, 1, projection=\"3d\")\nax.scatter(\n    coordinates[:, 0],\n    coordinates[:, 1],\n    coordinates[:, 2],\n    marker=\"o\",\n    c=predicted_target_features,\n    cmap=\"twilight\",\n)\nax.view_init(10, 135, 2)\nax.set_title(\"Predicted target features\")\nax.set_axis_off()\n\nax = fig.add_subplot(1, 2, 2, projection=\"3d\")\nax.scatter(\n    coordinates[:, 0],\n    coordinates[:, 1],\n    coordinates[:, 2],\n    marker=\"o\",\n    c=target_features_normalized[-1, :],\n    cmap=\"twilight\",\n)\nax.view_init(10, 135, 2)\nax.set_title(\"Actual target features\")\nax.set_axis_off()\nfig.colorbar(plt.cm.ScalarMappable(cmap=\"twilight\"), ax=ax)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}