{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Monitor memory usage at each BCD iteration with callbacks\n\nIn this example, we use a callback function to monitor memory usage\nat each iteration of the block-coordinate descent (BCD) algorithm.\nThis can be useful to detect memory leaks, or to check that the\nmemory usage is not too high for a given device.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import re\n\nfrom functools import partial\n\nimport matplotlib.pyplot as plt\nimport torch\n\nfrom fugw.mappings import FUGW\nfrom fugw.utils import _init_mock_distribution\nfrom rich.console import Console\nfrom rich.table import Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n\nn_points_source = 50\nn_points_target = 40\nn_features_train = 2\nn_features_test = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us generate random training data for the source and target distributions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, source_features_train, source_geometry, _ = _init_mock_distribution(\n    n_features_train, n_points_source\n)\n_, target_features_train, target_geometry, _ = _init_mock_distribution(\n    n_features_train, n_points_target\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Features and geometries should be normalized before calling the solver\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_features_train_normalized = source_features_train / torch.linalg.norm(\n    source_features_train, dim=1\n).reshape(-1, 1)\ntarget_features_train_normalized = target_features_train / torch.linalg.norm(\n    target_features_train, dim=1\n).reshape(-1, 1)\n\nsource_geometry_normalized = source_geometry / source_geometry.max()\ntarget_geometry_normalized = target_geometry / target_geometry.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a function to check memory usage at each iteration of the BCD\nalgorithm, as well as util functions to print relevant information.\nIn short, fugw callback functions receive `locals()`, which is a dictionary\nof all local variables in the current scope.\nThis allows us to access the tensors that are used in the BCD algorithm.\nIn particular, we filter our tensors that are on our device of interest,\nand we compute their respective memory usage.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def is_sparse(t):\n    return str(t.layout).find(\"sparse\") >= 0\n\n\ndef str_size(s):\n    m = re.match(r\"torch\\.Size\\(\\[(.*)\\]\\)\", str(s))\n    return f\"{m.group(1)}\"\n\n\ndef str_mem(mem, unit=\"KB\"):\n    if unit == \"KB\":\n        return f\"{mem / 1024:,.3f} KB\"\n    elif unit == \"MB\":\n        return f\"{mem / 1024 ** 2:,.3f} MB\"\n\n\ndef check_memory_usage(locals, device=torch.device(\"cpu\")):\n    console = Console()\n\n    variables = []\n    for name, value in locals.items():\n        if torch.is_tensor(value) and value.device == device:\n            variables.append([name, value])\n\n    variables = sorted(variables, key=lambda x: x[0].lower())\n\n    table = Table()\n    table.add_column(\"Variable\")\n    table.add_column(\"Size\", justify=\"right\")\n    table.add_column(\"Numel\", justify=\"right\")\n    table.add_column(\"Memory allocated\", justify=\"right\")\n\n    memory_allocated = 0\n    for name, value in variables:\n        if is_sparse(value):\n            s = value.size()\n            numel = value._nnz()\n            var_memory_allocated = numel * value.element_size()\n            table.add_row(\n                name, str_size(s), f\"{numel:,}\", str_mem(var_memory_allocated)\n            )\n        else:\n            s = value.size()\n            numel = value.numel()\n            var_memory_allocated = numel * value.element_size()\n            table.add_row(\n                name, str_size(s), f\"{numel:,}\", str_mem(var_memory_allocated)\n            )\n        memory_allocated += var_memory_allocated\n\n    table.add_section()\n    table.add_row(\n        f\"Total ({len(variables)})\",\n        \"\",\n        \"\",\n        str_mem(memory_allocated),\n        style=\"bold\",\n    )\n    console.print(table)\n\n    memory_at_bcd_step.append(memory_allocated)\n\n    if device.type == \"cuda\":\n        memory_lines = [\n            (\"Memory allocated\", str_mem(torch.cuda.memory_allocated(device))),\n            (\"Memory cached\", str_mem(torch.cuda.memory_cached(device))),\n            (\"Memory reserved\", str_mem(torch.cuda.memory_reserved(device))),\n        ]\n        console.log(\n            list(map(lambda x: f\"{x[0]}\\t{x[1]}\", memory_lines)).join(\"\\n\")\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us define the optimization problem to solve\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alpha = 0.5\nrho = 1000\neps = 1e-4\nmapping = FUGW(alpha=alpha, rho=rho, eps=eps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we fit a transport plan between source and target distributions\nusing a sinkhorn solver.\nOur callback function will be called at each iteration of the BCD algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\nmemory_at_bcd_step = []\n\n_ = mapping.fit(\n    source_features_train_normalized,\n    target_features_train_normalized,\n    source_geometry=source_geometry_normalized,\n    target_geometry=target_geometry_normalized,\n    solver=\"sinkhorn\",\n    solver_params={\n        \"nits_bcd\": 5,\n        \"nits_uot\": 100,\n    },\n    callback_bcd=partial(check_memory_usage, device=device),\n    device=device,\n    verbose=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we see that fugw's memory usage is constant.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 5))\nfig.suptitle(\"Memory usage at each BCD iteration\")\n\nax = fig.add_subplot()\nax.set_xlabel(\"BCD iteration\")\nax.set_xticks(range(len(memory_at_bcd_step)))\nax.set_ylabel(\"Memory allocated (KB)\")\nax.plot(memory_at_bcd_step)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}