{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Transport distributions using sparse solvers\n\nIn this example, we sample 2 toy distributions and compute\na sparse fugw alignment between them.\nSparse alignments are typically used when both aligned distributions\nhave more than 10k points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport torch\n\nfrom fugw.mappings import FUGW, FUGWSparse\nfrom fugw.scripts import coarse_to_fine\nfrom fugw.utils import init_mock_distribution\nfrom matplotlib.collections import LineCollection\nfrom scipy.sparse import coo_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(13)\n\nn_points_source = 300\nn_samples_source = 100\nn_points_target = 300\nn_samples_target = 100\nn_features_train = 2\nn_features_test = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us generate random training data for the source and target distributions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, source_features_train, _, source_embeddings = init_mock_distribution(\n    n_features_train, n_points_source\n)\n_, target_features_train, _, target_embeddings = init_mock_distribution(\n    n_features_train, n_points_target\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize the generated features:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(4, 4))\nax = fig.add_subplot()\nax.set_title(\"Source and target features\")\nax.set_aspect(\"equal\", \"datalim\")\nax.scatter(source_features_train[0], source_features_train[1], label=\"Source\")\nax.scatter(target_features_train[0], target_features_train[1], label=\"Target\")\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do not forget to normalize features and embeddings\nbefore fitting the models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_features_train_normalized = source_features_train / torch.linalg.norm(\n    source_features_train, dim=1\n).reshape(-1, 1)\ntarget_features_train_normalized = target_features_train / torch.linalg.norm(\n    target_features_train, dim=1\n).reshape(-1, 1)\n\nsource_embeddings_normalized, source_d_max = coarse_to_fine.random_normalizing(\n    source_embeddings\n)\ntarget_embeddings_normalized, target_d_max = coarse_to_fine.random_normalizing(\n    target_embeddings\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us define the coarse and fine-grained optimization problems to solve.\nWe also specify which solver to use at each of the 2 steps:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coarse_mapping = FUGW(alpha=0.5, eps=1e-4)\ncoarse_mapping_solver = \"mm\"\ncoarse_mapping_solver_params = {\n    \"tol_uot\": 1e-10,\n}\n\nfine_mapping = FUGWSparse(alpha=0.5, eps=1e-4)\nfine_mapping_solver = \"mm\"\nfine_mapping_solver_params = {\n    \"tol_uot\": 1e-10,\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let us fit both the coarse and fine-grained mappings.\nThe coarse mapping is fitted on a limited number\nof points from the source and target distributions,\nwhich we sample randomly in this example.\nYou should carefully set the source and target ``selection_radius``\nas they will greatly affect the sparsity of the computed mappings.\nThey should usally be set using domain knowledge related to the distributions\nyou are trying to align.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Sub-sample source and target distributions\nsource_sample = torch.randperm(n_points_source)[:n_samples_source]\ntarget_sample = torch.randperm(n_points_target)[:n_samples_target]\n\ncoarse_to_fine.fit(\n    # Source and target's features and embeddings\n    source_features=source_features_train_normalized,\n    target_features=target_features_train_normalized,\n    source_geometry_embeddings=source_embeddings_normalized,\n    target_geometry_embeddings=target_embeddings_normalized,\n    # Parametrize step 1 (coarse alignment between source and target)\n    source_sample=source_sample,\n    target_sample=target_sample,\n    coarse_mapping=coarse_mapping,\n    coarse_mapping_solver=coarse_mapping_solver,\n    coarse_mapping_solver_params=coarse_mapping_solver_params,\n    # Parametrize step 2 (selection of pairs of indices present in\n    # fine-grained's sparsity mask)\n    coarse_pairs_selection_method=\"topk\",\n    source_selection_radius=0.5 / source_d_max,\n    target_selection_radius=0.5 / target_d_max,\n    # Parametrize step 3 (fine-grained alignment)\n    fine_mapping=fine_mapping,\n    fine_mapping_solver=fine_mapping_solver,\n    fine_mapping_solver_params=fine_mapping_solver_params,\n    # Misc\n    verbose=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both the coarse and fine-grained transport plans can be accessed\nafter the models have been fitted\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Coarse transport plan's total mass: {coarse_mapping.pi.sum():.5f}\")\nprint(\n    \"Fine-grained transport plan's total mass:\"\n    f\" {torch.sparse.sum(fine_mapping.pi):.5f}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the evolution of the FUGW loss during training\nof the coarse mapping, with and without the entropic term:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(4, 4))\nax.set_title(\"Coarse mapping training loss\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"BCD step\")\nax.plot(coarse_mapping.loss_steps, coarse_mapping.loss, label=\"FUGW loss\")\nax.plot(\n    coarse_mapping.loss_steps,\n    coarse_mapping.loss_entropic,\n    label=\"FUGW entropic loss\",\n)\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And here is that of the fine-grained mapping:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(4, 4))\nax.set_title(\"Fine-grained mapping training loss\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"BCD step\")\nax.plot(fine_mapping.loss_steps, fine_mapping.loss, label=\"FUGW loss\")\nax.plot(\n    fine_mapping.loss_steps,\n    fine_mapping.loss_entropic,\n    label=\"FUGW entropic loss\",\n)\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, the computed sparse transport plan is not very sparse:\nit stores about 60% of what the equivalent dense transport plan\nwould store.\nWhen aligning distributions with a high number of points,\nwe usually want to keep this number much smaller.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sparsity_ratio = (\n    100 * fine_mapping.pi.values().shape[0] / fine_mapping.pi.shape.numel()\n)\nprint(f\"Ratio of non-null coefficients: {sparsity_ratio:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also have a look at the sparsity mask of the\nfine-grained transport plan. In this particular example,\nwe don't expect it to show a particularly meaningful structure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "indices = fine_mapping.pi.indices()\nfine_mapping_as_scipy_coo = coo_matrix(\n    (\n        fine_mapping.pi.values(),\n        (indices[0], indices[1]),\n    ),\n    shape=fine_mapping.pi.size(),\n)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.set_title(\"Sparsity mask of fine-grained mapping\")\nax.set_ylabel(\"Source vertices\")\nax.set_xlabel(\"Target vertices\")\nplt.spy(fine_mapping_as_scipy_coo, precision=\"present\", markersize=0.3)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can observe the computed mappings between source\nand target points in the feature space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pi = fine_mapping.pi.to_dense()\nfig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot()\nax.set_aspect(\"equal\", \"datalim\")\nax.set_title(\"Mapping\\ndisplayed in feature space\")\n\n# Draw lines between matched points\nindices = torch.cartesian_prod(\n    torch.arange(n_points_source), torch.arange(n_points_target)\n)\nsegments = torch.stack(\n    [\n        source_features_train[:, indices[:, 0]],\n        target_features_train[:, indices[:, 1]],\n    ]\n).permute(2, 0, 1)\npi_normalized = pi / pi.sum(dim=1).reshape(-1, 1)\nline_segments = LineCollection(\n    segments,\n    alpha=pi_normalized.flatten().nan_to_num(),\n    colors=\"black\",\n    lw=1,\n    zorder=1,\n)\nax.add_collection(line_segments)\n\n# Draw distributions\nax.scatter(source_features_train[0], source_features_train[1], label=\"Source\")\nax.scatter(target_features_train[0], target_features_train[1], label=\"Target\")\n\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, the fitted fine-grained model can transport unseen data\nbetween source and target\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_features_test = torch.rand(n_features_test, n_points_source)\ntarget_features_test = torch.rand(n_features_test, n_points_target)\ntransformed_data = fine_mapping.transform(source_features_test)\ntransformed_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert transformed_data.shape == target_features_test.shape"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}